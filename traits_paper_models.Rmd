---
title: "Analyses for 'The role of functional plant traits in determining vegetation distribution patterns in riparian landscapes"
author: "Emily J. Rollinson"
date: "Friday, January 30, 2015"
output: html_document
---

Import the community species abundance dataset  (should I be making a new one by cover and using that instead?) - yes, this now imports by cover for all species

```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/2012_cover_allsp.csv") #insert the  raw URL for the data file on github here
tempcover<- read.csv(text = raw) #read in the github file
```

Make a species cover matrix
```{r}
require(reshape)
tempcover<-cast(tempcover, Code ~ Species, value="Cover", fun.aggregate=sum)
tempcover<-as.data.frame(tempcover)
```

Make a copy of the cover matrix and reframe so that the site names are row names and not a column
```{r}
cover<-tempcover
rownames(cover)<-cover$Code
cover<-cover[,2:182]
```


Import the traits matrix and make sure all values are numeric

```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/TRY_traitsmatrix_quant_only2012sp_interpseedmass_absval.csv") #insert the  raw URL for the data file on github here
traits<- read.csv(text = raw, check.names = FALSE) #read in the github file
rownames(traits)<-traits$Trait
traits<-traits[,2:182]
```

playing with the FD functional diversity package - species have to be columns in the community dataset and rows in the traits dataset

```{r}
require(FD)
#transpose the traits matrix
traits_tp<-t(traits)
traits_tp<-as.data.frame(traits_tp)

pref_traits<-traits_tp[,c(6,9:11,21,26:28,33,36,38,42,43,46,47)]#making a smaller list of traits of particular interest
#6:leaf area
#9: leaf C/N
#10: leaf density
#11:leaf dry mass
#21: leaf N/P
#26: K per dry mass
#27: SLA
#28: leaf thickness
#33: photosynthesis per leaf area
#36 plant height vegetative
#38 plant relative growth rate
#42 root N per dry mass
#43 root depth
#46 seed mass
#47 seed number per reproduction unit


FD<-dbFD(pref_traits, cover, stand.x=FALSE, ord="podani", corr = "cailliez") #this is what worked



#try to make a species by species distance matrix to use in the Mouillot et al. method?


gowdist<-gowdis(pref_traits)
gowdist2<-as.matrix(gowdist)


#gowdis test data

ex1<-gowdis(dummy$trait)
ex1<-as.matrix(ex1)


```

reimport sites by traits

```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/site_by_trait_matrix_interp.csv") #insert the  raw URL for the data file on github here
sitebytrait<- read.csv(text = raw) #read in the github file
rownames(sitebytrait)<-sitebytrait$Site
sitebytrait<-sitebytrait[,2:57]
prcomp(sitebytrait)
```


ordinate PCA
```{r}

#remove traits with NAs
# column 17 has an NA
sitebytrait_noNA<-sitebytrait[,c(1:16,18:56)]

library(vegan)
ord <- metaMDS(sitebytrait_noNA, distance = "gower", k=2, trymax=50)
plot(ord)

#plot the ordination without traits showing, and with sites shown in text (this package is meant for sites/species so i am calling traits "species"")
#vegan interprets rows and columns as sites and species automatically, so you can just type "sites" or "species" for what you want to plot - you don't have to define those
#cex varies the text size

plot(ord, type="n")
text(ord, display ="sites", cex =0.7)

#plot to look at the sites with the traits names superimposed
plot(ord)
text(ord, display="species", cex=0.7)




#Trying a PCA


```
Trying a different package

```{r}
require(StatMatch)
test<-gower.dist(cover, traits)

require(cluster)
test<-daisy(traits, metric = "euclidean")
test<-as.data.frame(test)

require(vegan)  #this is working
test<-cca(cover, sitebytrait_noNA)
plot(test, type="n")
text(test, display="bp")
text(test, display="species")


test2<-test$CWM
```



trying new package 'cati'
```{r}
require(cati)
#transpose the community matrix
comm_tp<-(cover)
comm_tp<-as.data.frame(comm_tp)
indtraits<-AbToInd(sitebytrait_noNA, comm_tp, type.sp.val = "abundance")

ComIndex(traits = indtraits)


```



trying code to generate null communities myself
```{r}
reps<-100  #Number of replicates for each sample size
sites<-data.frame(as.factor(rownames(cover)))#sample sizes, in number of represented individuals
colnames(sites)[1]="sites"
sites_tp<-t(sites)
samples<-array(0,dim=c(2, length(sites_tp), reps))


for (j in 1:reps){
  samples[j, ] <-sample()
  
  
  


#so the method is to decide on the statistic that measures limiting similarity (and then environmental filtering), generate a null community, calculate that statistics, and iterate that enough times that i have a probability distribution of that statistic against which i can test each of my observeds.  use all species ever observed for null


#need to randomize the occurrence (cover) matrix keeping rows and column sums constant.  on each randomization calculate the statistic, save that, randomize again.


#pool.range<-c(20,100)    #range of species richness of total species pool (includes natives, exotics, and "bare spaces")
#NEprop<-c(.75,.15,.1)   #proportion of, respectively, natives, exotics, and bare spaces in pool (totals to 1)

#tot.pool<-round(runif(reps,pool.range[1],pool.range[2]))  #randomly generate [reps]-length vector of total pool sizes

#make a output matrix to fill all the different simulations (why we have a third dimension, so that it does not replace the earlier matrix)

http://stackoverflow.com/questions/24314878/compute-all-pairwise-differences-within-a-vector-in-r

min NND - for species i:length(species) in sites j:length(sites), calculate all pairwise distances using gowdist matrix and save the smallest of these.  

for (i in 1:sites){
  pairdist<-(j:k - j:k)   abs(apply(combn(1:length(species),2),2,diff))
  mNND<-min(pairdist[,2])
  
}


http://stackoverflow.com/questions/6422273/how-to-randomize-or-permute-a-dataframe-rowwise-and-columnwise

use sample or permatswap in vegan or randomizeMatrix in picante

output<-array(0,dim=c(2,length(sites),reps))

#loop to simulate the matrixes

for (j in 1:reps){

#determine pool composition for replicate
natives<-paste("N",c(1:round(NEprop[1]*tot.pool[j])))   #list of native species
exotics<-paste("E",c(1:round(NEprop[2]*tot.pool[j])))   #list of exotic species
zeros<-paste("Z",c(1:round(NEprop[3]*tot.pool[j]))) 
#list of free spaces
#allspp<-c(natives,exotics,zeros)                
#list of all species and blanks
  

#randomly construct simulated community

#ind.vec<-floor(rlnorm(length(allspp),8,1))      
#create list of abundances for each species, from lognormal abundance distribution

allspp<-paste("Species", c(1:round()))
comm<-rep(allspp[1],ind.vec[1])         
#populate first species in pool with its associated abundance

for(i in 2:length(allspp)) {            
#loop over all remaining species

comm<-c(comm,rep(allspp[i],ind.vec[i]))     
#populate remaining species with associated abundances

  }                         #close loop

for(i in 1:length(samps)) {                     
#Loop for different sample sizes

rs<-sample(comm,samps[i])                   #draw randomly from community pool of individuals with given sample size

output[1,i,j]<-length(unique(rs[is.element(rs,natives)]))   #total richness of natives in the sample

output[2,i,j]<-length(unique(rs[is.element(rs,exotics)]))   #total richness of exotics in the sample

}}  #end sample size loop






```





Nathan Kraft's test for null community assembly of traits (http://life.umd.edu/biology/kraftlab/Code_files/trait_tests.R)

The initial script defining functions (run before adding my own data)
///this only works for one trait.///
```{r}
## Nathan Kraft
## University of California, Berkeley 
## and currently
## Biodiversity Research Centre, University of British Columbia
## nkraft@biodiversity.ubc.ca

## Trait-based tests of community assembly in R

#The R functions posted here are free for you to download and use (under the terms of GNU GPL v2). The code offered is unsupported- I make no claims that they will work with your data or increase your general well being- but I am happy to answer questions. Please consider citing the related papers if you use them, modify them in your own research, or figure out how to solve a problem by looking at them.

## Simplification of functions used in:

#Kraft, N. J. B. and D. D. Ackerly. 2010. Functional trait and phylogenetic tests of community assembly across spatial scales in an Amazonian forest. Ecological Monographs 80:401-422.

#Kraft, N. J. B., R. Valencia, and D. Ackerly. 2008. Functional traits and niche-based tree community assembly in an Amazonian forest. Science 322:580-582.


# Fuctions come first in the file; example is at end. The key function is test_trait_data(); it requires all the other functions to run properly. 

## As a general warning, there is MINIMAL error/ safety checking in this code.  Use the example at the end of the file for formatting your data- I highly recommend that you wrap this code in something else to ensure that only complete datasets go into this function.  Also- Kurtosis is undefined for samples of less than 4, so the minimum community size for these tests is 4.  

## UPDATED June 5 2012 to correct an error in the calculation of SDNDr. 

#####################
### Functions #######
###########################################################



## BASIC TRAIT SPACE FUNCTIONS:

# Function to calculate the unbiased population estimate or the biased sample statistic of kurtosis. from http://www2.jura.uni-hamburg.de/instkrim/kriminologie/Mitarbeiter/Enzmann/Software/kurtosis.r Aug 2 2007


kurtosis=function(x, biased=F, na.rm=T)

{
 if (na.rm==T) x = x[!is.na(x)]
 n = length(x)
 if (n < 4)
 {
   if (na.rm==T)
   {
      cat('valid cases = ',n,'\nkurtosis is not defined for less than 4 valid cases!\n')
   }
   else
   {
      cat('cases = ',n,'\nkurtosis is not defined for less than 4 cases!\n')
   }
 }
 else
 {
   if (biased==T)
   {
      z = sqrt(n/(n-1))*scale(x)
      k = mean(z^4)-3
   }
   else
   {
      z = scale(x)
      k = sum(z^4)*n*(n+1)/((n-1)*(n-2)*(n-3))-3*(n-1)^2/((n-2)*(n-3))
   }
 k
 }
}

get_kurt=function(vect){
  return(kurtosis(vect))
	}

get_range=function(vect){
	r<-range(vect, na.rm=TRUE)
	return(r[2]-r[1])
	}
	
get_spacing=function(vect){
	vect<-vect[!is.na(vect)]
	vect[order(vect)]->v
	n<-length(v)
	spacing=NULL
	summary=NULL
	
	spacing[1]<-abs(v[1]-v[2])
	for (i in 2:(n-1)){
		first<-abs(v[i]-v[i-1])
		second<-abs(v[i]-v[i+1])
		spacing[i]<-min(first, second)
		}
	spacing[(length(spacing)+1)]<-abs(v[n]-v[n-1])
	summary$SDNN<-sd(spacing)
	summary$SDND<-sd(diff(sort(vect)))
	return(summary)
	}

get_var=function(vect){
	return(var(vect, na.rm=TRUE))
	}	
	
	
### Utility functions:
	
trim_pool_to_sample=function(restricted_sample,pool){
	sp<-unique(restricted_sample$sp)
	pool[(pool$sp %in% sp),]->np
	
	return(np)
	
	}


### Function to build a null distribution:

make_null=function(pool,richness,log=TRUE, reps=999, abweight=FALSE, abdata=NULL) {
	##abdata should be a sp x abund DF
	
	summary=NULL
	pool<-pool[!is.na(pool[2]),]
	if(log){
		pool[2]<-log10(pool[2])
		}
	
	if(abweight){
			merge(pool,abdata)->new
			new->pool
			}else{pool$abund<-1}
	

	
	for (i in 1:reps){
		sample(pool[,2], richness, prob=pool$abund)-> simcom
		##trait mean
		summary$mean[i]<-mean(simcom)
		##trait range
		summary$range[i]<-get_range(simcom)
		##spacing stats
		summary$var[i]<-get_var(simcom)
		space<-get_spacing(simcom)
		summary$SDNN[i]<-space$SDNN
		summary$SDNNr[i]<-space$SDNN/summary$range[i]
		summary$SDNDr[i]<-space$SDND/summary$range[i]
		summary$kurt[i]<-get_kurt(simcom)
		
				}
	summary<-as.data.frame(summary)
	return(summary)
	}
	

### Main function that puts it all together:

test_trait_data=function(sp_list, pool, log=TRUE, reps=999,abweight=FALSE, abdata=NULL, verbose=FALSE){
	
	
	community<-pool[pool$sp %in% sp_list,]
	
	dim(community)[1]->richness
	summary=NULL
	summary$test.richness<-richness
	summary$reps<-reps
	
	if(log){community[2]<-log10(community[2])}
	
	make_null(pool,richness, log=log, reps=reps, abweight=abweight, abdata=abdata)->nulldist
	summary$mean_rank<-sum(nulldist$mean<mean(community[,2]))
	summary$range_rank<-sum(nulldist$range<get_range(community[,2]))
	
	obspace<-get_spacing(community[,2])
	summary$SDNN_rank<-	sum(nulldist$SDNN<obspace$SDNN)
	summary$SDNNr_rank<-sum(nulldist$SDNNr<(obspace$SDNN/get_range(community[,2])))
	summary$SDNDr_rank<- sum(nulldist$SDNDr<(obspace$SDND/get_range(community[,2])))
	summary$kurt_rank<-	sum(nulldist$kurt<get_kurt(community[,2]))
	summary$var_rank<-	sum(nulldist$var<get_var(community[,2]))
	summary<-as.data.frame(summary)
	
	

	summary$obs_mean<-mean(community[,2])
	summary$null_mean_mean<-mean(nulldist$mean)
	summary$null_mean_sd<-sd(nulldist$mean)
		
	summary$obs_range<-get_range(community[,2])
	summary$null_mean_range<-mean(nulldist$range)
	summary$null_range_sd<-sd(nulldist$range)
		
	summary$obs_SDNN<-obspace$SDNN
	summary$null_mean_SDNN<-mean(nulldist$SDNN)
	summary$null_SDNN_sd<-sd(nulldist$SDNN)
		
	summary$obs_kurt<-get_kurt(community[,2])
	summary$null_mean_kurt<-mean(nulldist$kurt)
	summary$null_kurt_sd<-sd(nulldist$kurt)
		
	summary$obs_var<-get_var(community[,2])
	summary$null_mean_var<-mean(nulldist$var)
	summary$null_var_sd<-sd(nulldist$var)
		
	summary$obs_SDNNr<-summary$obs_SDNN/summary$obs_range
	summary$null_mean_SDNNr<-mean(nulldist$SDNNr)
	summary$null_SDNNr_sd<-sd(nulldist$SDNNr)
		
	summary$obs_SDNDr<-obspace$SDND/summary$obs_range
	summary$null_mean_SDNDr<-mean(nulldist$SDNDr)
	summary$null_SDNDr_sd<-sd(nulldist$SDNDr)

	
	summary$mean_ES<-(summary$obs_mean-summary$null_mean_mean )/summary$null_mean_sd
	summary$range_ES<-(summary$obs_range-summary$null_mean_range )/summary$null_range_sd
	summary$var_ES<-(summary$obs_var-summary$null_mean_var )/summary$null_var_sd
	summary$SDNN_ES<-(summary$obs_SDNN-summary$null_mean_SDNN )/summary$null_SDNN_sd
	summary$SDNNr_ES<-(summary$obs_SDNNr-summary$null_mean_SDNNr )/summary$null_SDNNr_sd
	summary$SDNDr_ES<-(summary$obs_SDNDr-summary$null_mean_SDNDr )/summary$null_SDNDr_sd
	summary$kurt_ES<-(summary$obs_kurt-summary$null_mean_kurt )/summary$null_kurt_sd
	
	if(verbose){
		return(summary)
		}else{ 
			return(summary[,c("test.richness", "reps", "mean_rank", "mean_ES", "range_rank", "range_ES", "var_rank", "var_ES", "SDNN_rank", "SDNN_ES", "SDNNr_rank", "SDNNr_ES", "SDNDr_rank", "SDNDr_ES", "kurt_rank", "kurt_ES")])  
			
			}
	
}

##################################
## END of functions ####
########################
```


then the actual analysis

```{r}
# note that all of the above code must be run in the console before the example below will function:


#####################################
## simple example with random data ##
#####################################

## Species list for a community to be tested:
sp_list_community<-c("a", "b","c","d", "e")


## the species pool to test the species list against (note that it must contain all species in the community!)
sp<-c("a", "b","c","d", "e", "f", "g", "h", "i", "j", "k", "l")
trait<-rlnorm(12,mean=5, sd=2)

pool<-data.frame(sp, trait)


##optional abundance vector for the species pool; must be in the same order as the species in the species pool data frame:
abundance<-floor(rlnorm(12,mean=5, sd=1))


## Example test, weighting species by abunance and log transforming the trait data prior to analysis:

test_trait_data(sp_list_community, pool, log=TRUE, reps=999, abweight=TRUE, abdata=abundance, verbose=TRUE)->summary_verbose

###if you just need effect sizes and ranks, set verbose=FALSE:
test_trait_data(sp_list_community, pool, log=TRUE, reps=999, abweight=TRUE, abdata=abundance, verbose=FALSE)->summary

### abundance weighting will change the output!
test_trait_data(sp_list_community, pool, log=TRUE, reps=999, abweight=FALSE, verbose=FALSE)->summary_pres_abs


## Description of arguments for test_trait_data()
#  sp_list  = vector of species names for local community
#  pool  	= data frame for species pool, col 1 must be named "sp" and includes species names, used to match to sp_list; col 2 can be called anything and is a continuous trait
#  log		= Logical- should trait data be logged?
#  reps		= number of null communities to build- should be no less than 999
#  abweight = logical- should species be sampled in the null based on abundance? If true, requires a vector for abdata
#  abdata   = vector of the abundances (absolute or relative) of species in the pool, used to weight null model draws.  Must be in same order as species in pool dataframe.  Required if abweight is TRUE.
#  verbose  = Logical.  How much information do you want in the output?  If FALSE, summary includes the ranks of the observed in the null and effect sizes.  If TRUE, summary also includes the observed value, the mean of the null, and the sd of the null for each metric.

## Description of output:
# test.richness = number of species in the community.
# reps 			= number of null randomizations performed
# ..._rank		= rank of the observed metric (e.g. range_rank) in the null.  Used with 'reps' to calculate a p-value.
# ..._ES		= standard effect size for a metric (e.g. range_ES), calculated as (obs-expected)/ (sd of null)
# obs_...		= value of a metric for the real community (e.g. obs_range)
# null_mean_... = mean of the null distribution of a given metric (e.g. null_mean_range)
# null_..._sd	= standard deviation of the null distrbution for a given metric (e.g. null_range_sd)

```


JUNK LEFTOVER CODE
-------------------------------------------------------------

Import a new community dataset with cover values
```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/2012_specieslist_herbcover.csv") #insert the  raw URL for the data file on github here
comm_cover_temp<- read.csv(text = raw) #read in the github file
```

Trim cover dataset to needed columns and read cover as numeric
```{r}
comm_cover_temp<-comm_cover_temp[,c(5:7,9)]
comm_cover_list<-rename(comm_cover_temp, c("Site.1"="Site", "Cover.."="Cover"))
comm_cover_list$Cover<-sapply(comm_cover_list$Cover, as.character)
comm_cover_list$Cover<-sapply(comm_cover_list$Cover, as.numeric)
```

Make a species cover matrix
```{r}
require(reshape)
comm_cover<-cast(comm_cover_list, Site ~ Species, value="Cover", fun.aggregate=sum)
comm_cover_quad<-as.data.frame(comm_cover_quad)
```


To make the NANs something else

quadmat[is.na(quadmat)] <- 00 #refills the empty cells with 0

to view the full dataset
```{r}
utils::View(comm)
```

///All below are practice - now deprecated code for a set of the traits data that had not been cleaned for units consistency, etc///

Import the list of quantitative traits and make sure all values are numeric
n.b. apparently if numeric values read in as factors, you have to go through converting to as.character and then to as.numeric to avoid R changing the values of the numbers in that column (which it was doing when I only used as.numeric)
there are a number of "x" values in the cover list, which were presences with such a minimal cover as to essentially be zero.  these are at the moment tranformed into NAs in this code and therefore absences

```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/TRY_quant_traits.csv") #insert the  raw URL for the data file on github here
traitstemp<- read.csv(text = raw) #read in the github file
traitstemp$Value<-sapply(traitstemp$Value, as.character)
traitstemp$Value<-sapply(traitstemp$Value, as.numeric)
```

Turn the traits list into a matrix, put  n/a for species/trait cells that do not have data
```{r}
require(reshape)
traitmatrix<-cast(traitstemp, Trait ~ Species, value='Value', fun.aggregate=mean)
```

to view the full dataset
```{r}
utils::View(comm)
```

export the traits list and community cover lists to Excel, since they have some mismatches in species content

oh - probably because it contains all species and the community list just contains herbaceous species at the moment because that is the only group of plants with cover estimates - so we're exporting to make a list with just herbaceous species.  Additionally the full traits list requested all species observed in 2012 intensive sampling and 2013 extensive sampling; not all 2013 species were observed in 2012, and those are removed from the truncated list as well
n.b. acer saccharum is still in both lists, seedlings had cover estimates

will need to rename Athyrium filix-femina var. angustum in comm data to Athyrium filix-femina to match trait data
same for Circaea lutetiana ssp. canadensis -> Circaea lutetiana
Maianthemum racemosum ssp. racemosum -> Maianthemum racemosum
also need to remove anything Genus sp. from comm list, and all the SP##
fix typo in comm, Hyperium mutilum to Hypericum mutilum

```{r}
write.table(traitmatrix, file="TRY_traitsmatrix.csv", sep=",", row.names=F)
write.table(comm_cover, file="2012_comm_cover.csv", sep=",", row.names=F)
```


reimport the data edited as above
```{r}
#community
comm2012<-read.csv("2012_comm_cover_herbs.csv")
rownames(comm2012)<-comm2012$Site
comm2012<-comm2012[,2:166]

#traits
traits2012<-read.csv("2012_TRY_traitsmatrix_herbs.csv")
rownames(traits2012)<-traits2012$Trait
traits2012<-traits2012[,2:166]

```


editing the dissimilarity matrix in excel: if a species has 5 or fewer missing distances, interpolate.  more than 5, remove species from analysis.

removed species (n=34):

Carex bullata
Didiplis.diandra
Dryopteris.camyloptera
Dryopteris.marginalis
Echinochloa.muricata
Eurybia.divaricata  
Eutrochium.purpureum
Halenia.deflexa
Hydrocotyle.americana
Hylotelephium.telephium
Lactuca.canadensis
Muhlenbergia.sobolifera
Oxalis.grandis
Paspalum.setaceum
Polygonum.arifolium
Polygonum.cespitosum
Polystichum.acrostichoides  
Potentilla.simplex
Rubus.pubescens
Rumex.triangulivalvis 
Sanicula.odorata
Scirpus.polyphyllus
Sinapis.arvensis
Smilax.glauca
Solanum.ptycanthum
Stellaria.pubera
Symphyotrichum.dumosum
Symphyotrichum.lateriflorum
Teucrium.canadense
Thalictrum.thalictroides
Trifolium.arvense 
Trifolium.campestre
Viola.fimbriatula
Viola.pubescens

```{r}
trim_trait_dis<-read.csv("2012_trait_dissimilarity_trim_averaged_NAs.csv")
rownames(trim_trait_dis)<-trim_trait_dis$X
trim_trait_dis<-trim_trait_dis[,2:132]
trim_trait_dis<-as.matrix(trim_trait_dis)
fit<-isoMDS(trim_trait_dis, k=2)
fit
x<-fit$points[,1]
y<-fit$points[,2]
plot(x,y)
```

rownames(traits2012)<-traits2012$Trait
traits2012<-traits2012[,2:132]


Make a trait dissimilarity matrix for the species
```{r}
require(cluster)
traitdiss<-daisy(traits2012trans2, metric = "euclidean")
traitdissim<-as.matrix(traitdiss)

#try FD again with trait dissim? - no, it won't allow NAs with that
#do I want gower or a different dissimilarity?

I think I can work with this dissimilarity matrix or another one and make decisions about interpolating NAs or deleting certain species or traits

write.table(traitdissim, file="2012_trait_dissimilarity.csv", sep=",", row.names=T)


```


It might be best to try the method as outlined in the proposal first using just a handful of traits, by hand, and then extend to the larger dataset at a later date.  Check - which traits show the most variation?  plot histograms

The partitioning of variation in trait states will work better with the qualitative traits, stick with those for the stuff by hand.  


Need to create a matrix with trait abundance values (site by trait, derived from site by species).  Potentially follow method in Ackerly and Cornwell 2007?

fill a new matrix - for each community, make columns for each trait, average trait values for each species in the community

would a species by trait matrix help?


Trying a new method RLQ following https://climateecology.wordpress.com/2013/09/03/r-for-ecologists-rlq-analysis-semi-explained/ (this will be great to transfer into the extensive sampling analysis as well, if it works with presence/absence; in the meantime just borrowing some info).  ok maybe not so helpful here

