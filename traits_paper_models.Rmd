---
title: "Analyses for 'The role of functional plant traits in determining vegetation distribution patterns in riparian landscapes"
author: "Emily J. Rollinson"
date: "Friday, January 30, 2015"
output: html_document
---

Import the community species abundance dataset  (should I be making a new one by cover and using that instead?) - yes, this now imports by cover for all species

```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/2012_cover_allsp.csv") #insert the  raw URL for the data file on github here
tempcover<- read.csv(text = raw) #read in the github file
```

Make a species cover matrix
```{r}
require(reshape)
tempcover<-cast(tempcover, Code ~ Species, value="Cover", fun.aggregate=sum)
tempcover<-as.data.frame(tempcover)
```

Make a copy of the cover matrix and reframe so that the site names are row names and not a column
```{r}
cover<-tempcover
rownames(cover)<-cover$Code
cover<-cover[,2:182]
```


Import the traits matrix and make sure all values are numeric

```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/TRY_traitsmatrix_quant_only2012sp_interpseedmass_absval.csv") #insert the  raw URL for the data file on github here
traits<- read.csv(text = raw, check.names = FALSE) #read in the github file
rownames(traits)<-traits$Trait
traits<-traits[,2:182]
```

playing with the FD functional diversity package - species have to be columns in the community dataset and rows in the traits dataset

```{r}
require(FD)
#transpose the traits matrix
traits_tp<-t(traits)
traits_tp<-as.data.frame(traits_tp)

pref_traits<-traits_tp[,c(6,9:11,21,26:28,33,36,38,42,43,46,47)]#making a smaller list of traits of particular interest
#6:leaf area
#9: leaf C/N
#10: leaf density
#11:leaf dry mass
#21: leaf N/P
#26: K per dry mass
#27: SLA
#28: leaf thickness
#33: photosynthesis per leaf area
#36 plant height vegetative
#38 plant relative growth rate
#42 root N per dry mass
#43 root depth
#46 seed mass
#47 seed number per reproduction unit

#pref_traits: 181 x 15 traits are columns
#cover: 24 x 181 species are columns


FD<-dbFD(pref_traits, cover, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE) 
export = FD[1:8]
test<-as.data.frame(export)
write.table(test, "functionaldiv2012.csv", sep=",")

#this is what worked
```

reimport sites by traits

```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/site_by_trait_matrix_interp.csv") #insert the  raw URL for the data file on github here
sitebytrait<- read.csv(text = raw) #read in the github file
rownames(sitebytrait)<-sitebytrait$Site
sitebytrait<-sitebytrait[,2:57]
prcomp(sitebytrait)
```


ordinate PCA
```{r}

#remove traits with NAs
# column 17 has an NA
sitebytrait_noNA<-sitebytrait[,c(1:16,18:56)]

library(vegan)
ord <- metaMDS(sitebytrait_noNA, distance = "gower", k=2, trymax=50)
plot(ord)

#plot the ordination without traits showing, and with sites shown in text (this package is meant for sites/species so i am calling traits "species"")
#vegan interprets rows and columns as sites and species automatically, so you can just type "sites" or "species" for what you want to plot - you don't have to define those
#cex varies the text size

plot(ord, type="n")
text(ord, display ="sites", cex =0.7)

#plot to look at the sites with the traits names superimposed
plot(ord)
text(ord, display="species", cex=0.7)

```



reimport Fdiversity values as a table
```{r}
require(lme4) #for GLMs
require(arm) #for display()
traitsdiv<-read.csv("FD.csv", check.names=TRUE) #oops i have two columns named as site; I can fix that (the first should be row.names) but for now just used the renamed Site.1 in the model

#Functional richness #something is wrong with the Fric values - recalculate and reimport.  it's meant to vary between 0 and 1 (therefore should be binomial).  higher is richer.  Oh they are all wrong - the whole thing shifted the column names one left of where they should be
Fric0<-glm(FRic ~ 1, family="quasipoisson", offset=log(Area), data=traitsdiv)
Fric1<-glm(FRic ~ River, family ="quasipoisson", offset=log(Area), data=traitsdiv)
Fric2<-glm(FRic ~ River/Site.1, family="quasipoisson", offset=log(Area), data=traitsdiv)
Fric3<-glm(FRic ~ River/Site.1/Bank, family="quasipoisson", offset=log(Area), data=traitsdiv)
display(Fric0)
display(Fric1)
display(Fric2)
display(Fric3)
anova(Fric0,Fric1,Fric2,Fric3, test="Chisq")
summary(Fric3)

model.matrix(Fric3) #use this on the model of interest (rich1, rich2, etc - to look at all the comparisons in the model matrix and confirm what contrasts go with which somewhat-obscure name in the summary)

#Functional evenness
FEve0<-glm(FEve ~ 1, family="quasipoisson", offset=log(Area), data=traitsdiv)
FEve1<-glm(FEve ~ River, family ="quasipoisson", offset=log(Area), data=traitsdiv)
FEve2<-glm(FEve ~ River/Site.1, family="quasipoisson", offset=log(Area), data=traitsdiv)
FEve3<-glm(FEve ~ River/Site.1/Bank, family="quasipoisson", offset=log(Area), data=traitsdiv)
display(FEve0)
display(FEve1)
display(FEve2)
display(FEve3)
anova(FEve0,FEve1,FEve2,FEve3, test="Chisq")
summary(FEve3)

#Functional diversity
FDiv0<-glm(FDiv ~ 1, family="quasipoisson", offset=log(Area), data=traitsdiv)
FDiv1<-glm(FDiv ~ River, family ="quasipoisson", offset=log(Area), data=traitsdiv)
FDiv2<-glm(FDiv ~ River/Site.1, family="quasipoisson", offset=log(Area), data=traitsdiv)
FDiv3<-glm(FDiv ~ River/Site.1/Bank, family="quasipoisson", offset=log(Area), data=traitsdiv)
display(FDiv0)
display(FDiv1)
display(FDiv2)
display(FDiv3)
anova(FDiv0,FDiv1,FDiv2,FDiv3, test="Chisq")
summary(FDiv3)


#RaoQ - varies between zero and 1 - should use binomial?
RaoQ0<-glm(RaoQ ~ 1, family="quasibinomial", offset=log(Area), data=traitsdiv)
RaoQ1<-glm(RaoQ ~ River, family ="quasibinomial", offset=log(Area), data=traitsdiv)
RaoQ2<-glm(RaoQ ~ River/Site.1, family="quasibinomial", offset=log(Area), data=traitsdiv)
RaoQ3<-glm(RaoQ ~ River/Site.1/Bank, family="quasibinomial", offset=log(Area), data=traitsdiv)
display(RaoQ0)
display(RaoQ1)
display(RaoQ2)
display(RaoQ3)
anova(RaoQ0,RaoQ1,RaoQ2,RaoQ3, test="Chisq")
summary(RaoQ3)


```

The most basic possible plot to look at all the points for greenline versus upslope, for whichever variable in "data" is desired:
```{r}
require(ggplot2)
qplot(data=traitsdiv, y=FDiv, x=Bank, geom("point"))

```

------------------------------------------------------------------------------------
*Native vs. introduced portions of the community*

```{r}
fulllist<-read.csv("2013_speciespresences_by_origin.csv", check.names=FALSE)

invs<-fulllist[1:308,1:3] #subset of the complete species list that are known introduced
nats<-fulllist[343:1545, 1:3] #subset of the complete species list that are known native

#omits species with unresolved origin status entirely (n=7 species; 34 observations)

require(reshape)
tempinvs<-cast(invs, River ~ Species, value="Presence", fun.aggregate=mean)
row.names(tempinvs)<-tempinvs$River
tempinvs2<-tempinvs[,2:62]
tempinvs3<-rapply(tempinvs2, f=function(x) ifelse(is.nan(x),0,x), how="replace")
tempinvs3<-as.data.frame(tempinvs3, check.names=FALSE)
row.names(tempinvs3)<-tempinvs$River
invcomm<-tempinvs3

tempnats<-cast(nats, River~Species, value="Presence", fun.aggregate=mean)
row.names(tempnats)<-tempnats$River
tempnats2<-tempnats[,2:213]
tempnats3<-rapply(tempnats2, f=function(x) ifelse(is.nan(x),0,x), how="replace")
tempnats3<-as.data.frame(tempnats3)
row.names(tempnats3)<-tempnats$River
natcomm<-tempnats3


#import traits matrices for inv and nat 2013 species (do i need these? yes

invtraits<-read.csv("2013_traits_invs.csv")
nattraits<-read.csv("2013_traits_natives.csv")

row.names(invtraits)<-invtraits$Trait
invtraits2<-invtraits[,2:61]

row.names(nattraits)<-nattraits$Trait
nattraits2<-nattraits[,2:189]

#import full 2013 traits matrix (no, would have to prune the NIs.  just merge the two above.)

alltraits<-merge(invtraits, nattraits)

#no, what i need is a site x trait matrix for nats and invs and then merge the site x trait matrices


#transpose for FD 
tinvtraits<-t(invtraits2)
tinvtraits<-as.data.frame(tinvtraits)
tnattraits<-t(nattraits2)
tnattraits<-as.data.frame(tnattraits)

#community matrix has an error invcomm contains Cynanchum louiseae and traits matrix does not.  Remove from invcomm it is column 12
#same error for natives, many in community list but no traits

#25 brachyelytrum aristosum
#43 cornus obliqua
#51 doellengeria umbellata
#55 elymus canadensis
#67 eurybia divaricata
#68 euthamia caroliniana
#70 eutrochium maculatum
#71 euthrochium purpureum
#82 gentiana linearis
#86 helianthus divaricatus
#89 heuchera villosa
#118 oclemena acuminata
#135 polygonum arifolium
#136 polygonum cilinode
#145 prenanthes altissima
#146 prenanthes trifoliata
#153 quercus prenoides
#175 smilax tamnoides
#180 solidago latissimifolia
#182 stellaria pubera
#183 symphyotrichum dumosum
#185 symphyotrichum novae.angleae
#190 thalictrum thalictroides
#196 triadenum virginicum
#211 woodsia obtusa

invcomm2<-invcomm[,c(1:11,13:61)]

natcomm2<-natcomm[,c(1:24,26:42, 44:50, 52:54,56:66,69,72:81,83:85,87,88,90:117, 119:134, 137:144, 147:152,154:174,176:179,181,184,186:189,191:195,197:210,212)]


#pref_traits: 181 x 15 traits are columns
#cover: 24 x 181 species are columns

#tnattraits: 188 x 76, traits are columns
#natcomm2: 53 x 188, species are columns

#tinvtraits 60 x 76, traits are columns
#invcomm2: 53 x 60, species are columns
#distance matrix?

#FDnat<-dbFD(tinvtraits, invcomm2, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE)
#FDinv<-dbFD(tnattraits, natcomm2, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE )

#ok, need to do the same export-and-interpolate for the traits matrix as I did for the first FD
#seed mass was missing for 2 species, gave it the median (inv traits)
#seed mass missing for 29 species, give them the median (nat traits)

write.table(tnattraits, "2013nativetraits.csv", sep=",")
write.table(tinvtraits, "2013invtraits.csv", sep=",")


#needed to delete eleocharis intermedia from traits before reimporting, it wasn't in comm data (native species)

#reimport traits data

invtrt<-read.csv("2013invtraits_interp.csv")
row.names(invtrt)<-invtrt$X
invtrt<-invtrt[,2:63]

nattrt<-read.csv("2013nativetraits_interp.csv")
row.names(nattrt)<-nattrt$X
nattrt<-nattrt[,2:66]


# i think i need to try resaving these csvs with everything set to numeric in excel, delete the totally NA traits (no data for any species in the subset), deleting the extra rows
#the same traits should also be used for native and invasive distance matrices, so once these are reimported as edited above,  make preferred-trait subsets that have matching traits


FDinv<-dbFD(invtrt, invcomm2, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE)
FDnat<-dbFD(nattrt, natcomm2, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE )


#throwing an error  Species labels in 'x' and 'a' need to be identical and ordered alphabetically (or simply in the same order). for natives; invasives are working.  export nattrt and natcomm2 to check quickly in excel.  The issue is misspelling = "Oenothera biennis" in the traits file and Oenethera biennis in the community file.  Oenothera is the correct spelling; change the name of that column in the community file.  

#write.table(nattrt, "testfile_nativetraits.csv", sep=",", row.names=TRUE)
#write.table(natcomm2, "testfile_nativecomm.csv", sep=",", row.names=TRUE)
#can delete those tables now

names(natcomm2)[names(natcomm2)=="Oenethera.biennis"] <- "Oenothera.biennis"



#export $CWM from this to get the traits matrix to then marge back together and compare community distances.
#for future reference 'functcomp' returns the community level weighted means, don't have to run all other things in 'dbFD'

inv_sitebytrait<-FDinv$CWM
nat_sitebytrait<-FDnat$CWM

#write these to tables so i have them saved in case the code magically dies
write.table(inv_sitebytrait, "sitebytraitmatrix_inv2013.csv", sep=",", row.names=TRUE, col.names=TRUE)
write.table(nat_sitebytrait, "sitebytraitmatrix_nat2013.csv", sep=",", row.names=TRUE, col.names=TRUE)


#reimport the site by trait matrix that has been pruned to shared/preferred traits and lists communities separately as invasive and native portions of each site.

partcomm<-read.csv("2013_sitebytraitmatrix_partitionedbyorigin.csv")
row.names(partcomm)<-partcomm$Comm
partcomm<-partcomm[,3:23]


#rough interpolation to allow ordination to proceed  - give any NA the median value for that column
fx=function(x){
  x[is.na(x)]=median(x, na.rm=TRUE)
  x
}
int_partcomm=data.frame(apply(int_partcomm,2,fx))



#Ordinate that matrix

require(vegan)
ord<-metaMDS(int_partcomm, distance="gower", noshare=FALSE, zerodist="add", k=3)
ordiplot(ord, type="n", xlim=c(-0.3,0.5), ylim=c(-0.3, 0.5))
type=c(rep("Introduced", 53), rep("Native", 53))
#ordihull(ord, groups=type, draw="polygon", col="grey90", label=F) #for tightest convex hull containing all points in the group
ordiellipse(ord, groups=type, draw="lines", kind="sd", col="black", label=T) #for ellipse representing SD of community

points(ord, display="sites", col=c(rep("red", 53), rep("blue", 53)), pch= 19)

orditorp(ord, display="species", col="black", pch=8) #this will plot the traits ("species" in vegan package lingo which always means whatever your columns are)


#test significance
anosim(int_partcomm, type)


#try to make a species by species distance matrix to use in the Mouillot et al. method?
#gowdist<-gowdis(pref_traits)
#gowdist2<-as.matrix(gowdist)

#gowdis test data

ex1<-gowdis(dummy$trait)
ex1<-as.matrix(ex1)
```





------------------------------------------------------------------------------------
*Null community assembly*

http://stackoverflow.com/questions/6422273/how-to-randomize-or-permute-a-dataframe-rowwise-and-columnwise

use sample or permatswap in vegan or randomizeMatrix in picante

```{r}
require(vegan)

#I think I have to use count data for this rather than cover data
matrix<-read.csv("2012_abundancematrix_modified.csv")
row.names(matrix)<-matrix$Site
comm<-matrix[,4:246]
test<-permatswap(comm, method="quasiswap", fixedmar="both", shuffle = "samp", strata = NULL, mtype="count", times=99)



#somehow need to iterate FD across this
#need to load in the traits data
require(picante)
require(FD)
rep=99
permute<-matrix(nrow=rep, ncol=4)
for (i in 1:rep) {
  temp<-randomizeMatrix(cover, null.model="independentswap", iterations = 1000)
  FDtemp<-dbFD(pref_traits, temp, stand.x=TRUE, ord="podani", corr = "cailliez") #this is silly I don't need FD in here, I need something like NND and maxD after Mouillot et al.  but maybe this will tell me something else 
  permute[i, ] <-c(mean(FDtemp$FEve), mean(FDtemp$FDiv), mean(FDtemp$FDis), mean(FDtemp$RaoQ))
}

FEvehist<-permute[,1]
hist(FEvehist, breaks=100)
abline(v=0.670, lwd=2, col="purple") #this isn't plotting and also is an inaccurate test since i am plotting a single community value on a histogram of mean FEves across all communities.  

#maybe make an array and save the value for each community and test each community against its own null distribution??
#this isn't working
#require(picante)
#require(FD)
#rep=2
#array<-array(0, dim=c(rep,24,4))
#for (i in 1:rep) {
 # temp<-randomizeMatrix(cover, null.model="independentswap", iterations = 1000)
 # FDtemp<-dbFD(pref_traits, temp, stand.x=TRUE, ord="podani", corr = "cailliez")
 # FEve = FDtemp$FEve
 # FDiv = FDtemp$FDiv
 # FDis = FDtemp$FDis
#  RaoQ = FDtemp$RaoQ
#  for (j in 1:24){
#  array[i,j, ] <-c(FEve, FDiv, FDis, RaoQ)
#  }
#}

#Trying a different approach

require(picante)
require(FD)
rep=999
permFEve<-matrix(nrow=rep, ncol=24)
permFDiv<-matrix(nrow=rep, ncol=24)
permFDis<-matrix(nrow=rep, ncol=24)
permRaoQ<-matrix(nrow=rep, ncol=24)
for (i in 11:rep) {
  temp<-randomizeMatrix(cover, null.model="independentswap", iterations = 1000)
  try(FDtemp<-dbFD(pref_traits, temp, stand.x=TRUE, ord="podani", corr = "cailliez"), silent=TRUE)
  FEve = FDtemp$FEve
  FDiv = FDtemp$FDiv
  FDis = FDtemp$FDis
  RaoQ = FDtemp$RaoQ
  permFEve[i,]<-FEve
  permFDiv[i,]<-FDiv
  permFDis[i,]<-FDis
  permRaoQ[i,]<-RaoQ
}

#this will provide each row as a permutation and each column as one of the communities, with a separate table for each statistic.  This can be used to test each community for environmental filtering etc once I figure out how to calculate probabilities on the histogram i made)

is it just if my values fall outside 0.025 and .975?  

#Export the null tables so I don't have to run this again.  

write.table(permFDis, file="nullFDis.csv", sep=",")
write.table(permFDiv, file="nullFDiv.csv", sep=",")
write.table(permFEve, file="nullFEve.csv", sep=",")
write.table(permRaoQ, file="nullRaoQ.csv", sep=",")

```

#get quantiles
quant.hu <- apply(test, 2, quantile, probs = c(.025, .975))
q.dat <- melt(data.frame(t(quant.hu)))
q.dat2 <- cbind(q.dat, num=rep(1:25, 2))

Code for checking the distribution - plotting a dist on a histogram???
> hist(traitsdiv$FDiv)
> x<-traitsdiv$FDiv
> h<-hist(x, breaks=10)
> xfit<-seq(min(x), max(x), length=40)
> yfit<-dpoisson(xfit, mean=mean(x), sd=sd(x))
Error: could not find function "dpoisson"
> ??functions
> yfit<-ppois(xfit, mean=mean(x), sd=sd(x))
Error in ppois(xfit, mean = mean(x), sd = sd(x)) : 
  unused arguments (mean = mean(x), sd = sd(x))
> yfit<-ppois(xfit)
Error in ppois(xfit) : argument "lambda" is missing, with no default
> yfit<-ppois(xfit)
Error in ppois(xfit) : argument "lambda" is missing, with no default
> help(ppois)
> yfit<-ppois(xfit, lambda=mean(x))
> yfit<-yfit*diff(h$mids[1:2]*length(x))
> lines(xfit, yfit, col="blue", lwd=2)

JUNK LEFTOVER CODE
------------------------------------------------------------


trying new package 'cati'
```{r}
require(cati)
#transpose the community matrix
comm_tp<-(cover)
comm_tp<-as.data.frame(comm_tp)
indtraits<-AbToInd(sitebytrait_noNA, comm_tp, type.sp.val = "abundance")

ComIndex(traits = indtraits)


```



trying code to generate null communities myself
```{r}
reps<-100  #Number of replicates for each sample size
sites<-data.frame(as.factor(rownames(cover)))#sample sizes, in number of represented individuals
colnames(sites)[1]="sites"
sites_tp<-t(sites)
samples<-array(0,dim=c(2, length(sites_tp), reps))


for (j in 1:reps){
  samples[j, ] <-sample()
  
  
  


#so the method is to decide on the statistic that measures limiting similarity (and then environmental filtering), generate a null community, calculate that statistics, and iterate that enough times that i have a probability distribution of that statistic against which i can test each of my observeds.  use all species ever observed for null


#need to randomize the occurrence (cover) matrix keeping rows and column sums constant.  on each randomization calculate the statistic, save that, randomize again.


#pool.range<-c(20,100)    #range of species richness of total species pool (includes natives, exotics, and "bare spaces")
#NEprop<-c(.75,.15,.1)   #proportion of, respectively, natives, exotics, and bare spaces in pool (totals to 1)

#tot.pool<-round(runif(reps,pool.range[1],pool.range[2]))  #randomly generate [reps]-length vector of total pool sizes

#make a output matrix to fill all the different simulations (why we have a third dimension, so that it does not replace the earlier matrix)

http://stackoverflow.com/questions/24314878/compute-all-pairwise-differences-within-a-vector-in-r

min NND - for species i:length(species) in sites j:length(sites), calculate all pairwise distances using gowdist matrix and save the smallest of these.  

for (i in 1:sites){
  pairdist<-(j:k - j:k)   abs(apply(combn(1:length(species),2),2,diff))
  mNND<-min(pairdist[,2])
  
}


http://stackoverflow.com/questions/6422273/how-to-randomize-or-permute-a-dataframe-rowwise-and-columnwise

use sample or permatswap in vegan or randomizeMatrix in picante

output<-array(0,dim=c(2,length(sites),reps))

#loop to simulate the matrixes

for (j in 1:reps){

#determine pool composition for replicate
natives<-paste("N",c(1:round(NEprop[1]*tot.pool[j])))   #list of native species
exotics<-paste("E",c(1:round(NEprop[2]*tot.pool[j])))   #list of exotic species
zeros<-paste("Z",c(1:round(NEprop[3]*tot.pool[j]))) 
#list of free spaces
#allspp<-c(natives,exotics,zeros)                
#list of all species and blanks
  

#randomly construct simulated community

#ind.vec<-floor(rlnorm(length(allspp),8,1))      
#create list of abundances for each species, from lognormal abundance distribution

allspp<-paste("Species", c(1:round()))
comm<-rep(allspp[1],ind.vec[1])         
#populate first species in pool with its associated abundance

for(i in 2:length(allspp)) {            
#loop over all remaining species

comm<-c(comm,rep(allspp[i],ind.vec[i]))     
#populate remaining species with associated abundances

  }                         #close loop

for(i in 1:length(samps)) {                     
#Loop for different sample sizes

rs<-sample(comm,samps[i])                   #draw randomly from community pool of individuals with given sample size

output[1,i,j]<-length(unique(rs[is.element(rs,natives)]))   #total richness of natives in the sample

output[2,i,j]<-length(unique(rs[is.element(rs,exotics)]))   #total richness of exotics in the sample

}}  #end sample size loop






```





Nathan Kraft's test for null community assembly of traits (http://life.umd.edu/biology/kraftlab/Code_files/trait_tests.R)

The initial script defining functions (run before adding my own data)
///this only works for one trait.///
```{r}
## Nathan Kraft
## University of California, Berkeley 
## and currently
## Biodiversity Research Centre, University of British Columbia
## nkraft@biodiversity.ubc.ca

## Trait-based tests of community assembly in R

#The R functions posted here are free for you to download and use (under the terms of GNU GPL v2). The code offered is unsupported- I make no claims that they will work with your data or increase your general well being- but I am happy to answer questions. Please consider citing the related papers if you use them, modify them in your own research, or figure out how to solve a problem by looking at them.

## Simplification of functions used in:

#Kraft, N. J. B. and D. D. Ackerly. 2010. Functional trait and phylogenetic tests of community assembly across spatial scales in an Amazonian forest. Ecological Monographs 80:401-422.

#Kraft, N. J. B., R. Valencia, and D. Ackerly. 2008. Functional traits and niche-based tree community assembly in an Amazonian forest. Science 322:580-582.


# Fuctions come first in the file; example is at end. The key function is test_trait_data(); it requires all the other functions to run properly. 

## As a general warning, there is MINIMAL error/ safety checking in this code.  Use the example at the end of the file for formatting your data- I highly recommend that you wrap this code in something else to ensure that only complete datasets go into this function.  Also- Kurtosis is undefined for samples of less than 4, so the minimum community size for these tests is 4.  

## UPDATED June 5 2012 to correct an error in the calculation of SDNDr. 

#####################
### Functions #######
###########################################################



## BASIC TRAIT SPACE FUNCTIONS:

# Function to calculate the unbiased population estimate or the biased sample statistic of kurtosis. from http://www2.jura.uni-hamburg.de/instkrim/kriminologie/Mitarbeiter/Enzmann/Software/kurtosis.r Aug 2 2007


kurtosis=function(x, biased=F, na.rm=T)

{
 if (na.rm==T) x = x[!is.na(x)]
 n = length(x)
 if (n < 4)
 {
   if (na.rm==T)
   {
      cat('valid cases = ',n,'\nkurtosis is not defined for less than 4 valid cases!\n')
   }
   else
   {
      cat('cases = ',n,'\nkurtosis is not defined for less than 4 cases!\n')
   }
 }
 else
 {
   if (biased==T)
   {
      z = sqrt(n/(n-1))*scale(x)
      k = mean(z^4)-3
   }
   else
   {
      z = scale(x)
      k = sum(z^4)*n*(n+1)/((n-1)*(n-2)*(n-3))-3*(n-1)^2/((n-2)*(n-3))
   }
 k
 }
}

get_kurt=function(vect){
  return(kurtosis(vect))
	}

get_range=function(vect){
	r<-range(vect, na.rm=TRUE)
	return(r[2]-r[1])
	}
	
get_spacing=function(vect){
	vect<-vect[!is.na(vect)]
	vect[order(vect)]->v
	n<-length(v)
	spacing=NULL
	summary=NULL
	
	spacing[1]<-abs(v[1]-v[2])
	for (i in 2:(n-1)){
		first<-abs(v[i]-v[i-1])
		second<-abs(v[i]-v[i+1])
		spacing[i]<-min(first, second)
		}
	spacing[(length(spacing)+1)]<-abs(v[n]-v[n-1])
	summary$SDNN<-sd(spacing)
	summary$SDND<-sd(diff(sort(vect)))
	return(summary)
	}

get_var=function(vect){
	return(var(vect, na.rm=TRUE))
	}	
	
	
### Utility functions:
	
trim_pool_to_sample=function(restricted_sample,pool){
	sp<-unique(restricted_sample$sp)
	pool[(pool$sp %in% sp),]->np
	
	return(np)
	
	}


### Function to build a null distribution:

make_null=function(pool,richness,log=TRUE, reps=999, abweight=FALSE, abdata=NULL) {
	##abdata should be a sp x abund DF
	
	summary=NULL
	pool<-pool[!is.na(pool[2]),]
	if(log){
		pool[2]<-log10(pool[2])
		}
	
	if(abweight){
			merge(pool,abdata)->new
			new->pool
			}else{pool$abund<-1}
	

	
	for (i in 1:reps){
		sample(pool[,2], richness, prob=pool$abund)-> simcom
		##trait mean
		summary$mean[i]<-mean(simcom)
		##trait range
		summary$range[i]<-get_range(simcom)
		##spacing stats
		summary$var[i]<-get_var(simcom)
		space<-get_spacing(simcom)
		summary$SDNN[i]<-space$SDNN
		summary$SDNNr[i]<-space$SDNN/summary$range[i]
		summary$SDNDr[i]<-space$SDND/summary$range[i]
		summary$kurt[i]<-get_kurt(simcom)
		
				}
	summary<-as.data.frame(summary)
	return(summary)
	}
	

### Main function that puts it all together:

test_trait_data=function(sp_list, pool, log=TRUE, reps=999,abweight=FALSE, abdata=NULL, verbose=FALSE){
	
	
	community<-pool[pool$sp %in% sp_list,]
	
	dim(community)[1]->richness
	summary=NULL
	summary$test.richness<-richness
	summary$reps<-reps
	
	if(log){community[2]<-log10(community[2])}
	
	make_null(pool,richness, log=log, reps=reps, abweight=abweight, abdata=abdata)->nulldist
	summary$mean_rank<-sum(nulldist$mean<mean(community[,2]))
	summary$range_rank<-sum(nulldist$range<get_range(community[,2]))
	
	obspace<-get_spacing(community[,2])
	summary$SDNN_rank<-	sum(nulldist$SDNN<obspace$SDNN)
	summary$SDNNr_rank<-sum(nulldist$SDNNr<(obspace$SDNN/get_range(community[,2])))
	summary$SDNDr_rank<- sum(nulldist$SDNDr<(obspace$SDND/get_range(community[,2])))
	summary$kurt_rank<-	sum(nulldist$kurt<get_kurt(community[,2]))
	summary$var_rank<-	sum(nulldist$var<get_var(community[,2]))
	summary<-as.data.frame(summary)
	
	

	summary$obs_mean<-mean(community[,2])
	summary$null_mean_mean<-mean(nulldist$mean)
	summary$null_mean_sd<-sd(nulldist$mean)
		
	summary$obs_range<-get_range(community[,2])
	summary$null_mean_range<-mean(nulldist$range)
	summary$null_range_sd<-sd(nulldist$range)
		
	summary$obs_SDNN<-obspace$SDNN
	summary$null_mean_SDNN<-mean(nulldist$SDNN)
	summary$null_SDNN_sd<-sd(nulldist$SDNN)
		
	summary$obs_kurt<-get_kurt(community[,2])
	summary$null_mean_kurt<-mean(nulldist$kurt)
	summary$null_kurt_sd<-sd(nulldist$kurt)
		
	summary$obs_var<-get_var(community[,2])
	summary$null_mean_var<-mean(nulldist$var)
	summary$null_var_sd<-sd(nulldist$var)
		
	summary$obs_SDNNr<-summary$obs_SDNN/summary$obs_range
	summary$null_mean_SDNNr<-mean(nulldist$SDNNr)
	summary$null_SDNNr_sd<-sd(nulldist$SDNNr)
		
	summary$obs_SDNDr<-obspace$SDND/summary$obs_range
	summary$null_mean_SDNDr<-mean(nulldist$SDNDr)
	summary$null_SDNDr_sd<-sd(nulldist$SDNDr)

	
	summary$mean_ES<-(summary$obs_mean-summary$null_mean_mean )/summary$null_mean_sd
	summary$range_ES<-(summary$obs_range-summary$null_mean_range )/summary$null_range_sd
	summary$var_ES<-(summary$obs_var-summary$null_mean_var )/summary$null_var_sd
	summary$SDNN_ES<-(summary$obs_SDNN-summary$null_mean_SDNN )/summary$null_SDNN_sd
	summary$SDNNr_ES<-(summary$obs_SDNNr-summary$null_mean_SDNNr )/summary$null_SDNNr_sd
	summary$SDNDr_ES<-(summary$obs_SDNDr-summary$null_mean_SDNDr )/summary$null_SDNDr_sd
	summary$kurt_ES<-(summary$obs_kurt-summary$null_mean_kurt )/summary$null_kurt_sd
	
	if(verbose){
		return(summary)
		}else{ 
			return(summary[,c("test.richness", "reps", "mean_rank", "mean_ES", "range_rank", "range_ES", "var_rank", "var_ES", "SDNN_rank", "SDNN_ES", "SDNNr_rank", "SDNNr_ES", "SDNDr_rank", "SDNDr_ES", "kurt_rank", "kurt_ES")])  
			
			}
	
}

##################################
## END of functions ####
########################
```


then the actual analysis

```{r}
# note that all of the above code must be run in the console before the example below will function:


#####################################
## simple example with random data ##
#####################################

## Species list for a community to be tested:
sp_list_community<-c("a", "b","c","d", "e")


## the species pool to test the species list against (note that it must contain all species in the community!)
sp<-c("a", "b","c","d", "e", "f", "g", "h", "i", "j", "k", "l")
trait<-rlnorm(12,mean=5, sd=2)

pool<-data.frame(sp, trait)


##optional abundance vector for the species pool; must be in the same order as the species in the species pool data frame:
abundance<-floor(rlnorm(12,mean=5, sd=1))


## Example test, weighting species by abunance and log transforming the trait data prior to analysis:

test_trait_data(sp_list_community, pool, log=TRUE, reps=999, abweight=TRUE, abdata=abundance, verbose=TRUE)->summary_verbose

###if you just need effect sizes and ranks, set verbose=FALSE:
test_trait_data(sp_list_community, pool, log=TRUE, reps=999, abweight=TRUE, abdata=abundance, verbose=FALSE)->summary

### abundance weighting will change the output!
test_trait_data(sp_list_community, pool, log=TRUE, reps=999, abweight=FALSE, verbose=FALSE)->summary_pres_abs


## Description of arguments for test_trait_data()
#  sp_list  = vector of species names for local community
#  pool  	= data frame for species pool, col 1 must be named "sp" and includes species names, used to match to sp_list; col 2 can be called anything and is a continuous trait
#  log		= Logical- should trait data be logged?
#  reps		= number of null communities to build- should be no less than 999
#  abweight = logical- should species be sampled in the null based on abundance? If true, requires a vector for abdata
#  abdata   = vector of the abundances (absolute or relative) of species in the pool, used to weight null model draws.  Must be in same order as species in pool dataframe.  Required if abweight is TRUE.
#  verbose  = Logical.  How much information do you want in the output?  If FALSE, summary includes the ranks of the observed in the null and effect sizes.  If TRUE, summary also includes the observed value, the mean of the null, and the sd of the null for each metric.

## Description of output:
# test.richness = number of species in the community.
# reps 			= number of null randomizations performed
# ..._rank		= rank of the observed metric (e.g. range_rank) in the null.  Used with 'reps' to calculate a p-value.
# ..._ES		= standard effect size for a metric (e.g. range_ES), calculated as (obs-expected)/ (sd of null)
# obs_...		= value of a metric for the real community (e.g. obs_range)
# null_mean_... = mean of the null distribution of a given metric (e.g. null_mean_range)
# null_..._sd	= standard deviation of the null distrbution for a given metric (e.g. null_range_sd)

```
Trying a different package

```{r}
require(StatMatch)
test<-gower.dist(cover, traits)

require(cluster)
test<-daisy(traits, metric = "euclidean")
test<-as.data.frame(test)

require(vegan)  #this is working
test<-cca(cover, sitebytrait_noNA)
plot(test, type="n")
text(test, display="bp")
text(test, display="species")


test2<-test$CWM
```

-

Import a new community dataset with cover values
```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/2012_specieslist_herbcover.csv") #insert the  raw URL for the data file on github here
comm_cover_temp<- read.csv(text = raw) #read in the github file
```

Trim cover dataset to needed columns and read cover as numeric
```{r}
comm_cover_temp<-comm_cover_temp[,c(5:7,9)]
comm_cover_list<-rename(comm_cover_temp, c("Site.1"="Site", "Cover.."="Cover"))
comm_cover_list$Cover<-sapply(comm_cover_list$Cover, as.character)
comm_cover_list$Cover<-sapply(comm_cover_list$Cover, as.numeric)
```

Make a species cover matrix
```{r}
require(reshape)
comm_cover<-cast(comm_cover_list, Site ~ Species, value="Cover", fun.aggregate=sum)
comm_cover_quad<-as.data.frame(comm_cover_quad)
```


To make the NANs something else

quadmat[is.na(quadmat)] <- 00 #refills the empty cells with 0

to view the full dataset
```{r}
utils::View(comm)
```

///All below are practice - now deprecated code for a set of the traits data that had not been cleaned for units consistency, etc///

Import the list of quantitative traits and make sure all values are numeric
n.b. apparently if numeric values read in as factors, you have to go through converting to as.character and then to as.numeric to avoid R changing the values of the numbers in that column (which it was doing when I only used as.numeric)
there are a number of "x" values in the cover list, which were presences with such a minimal cover as to essentially be zero.  these are at the moment tranformed into NAs in this code and therefore absences

```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/TRY_quant_traits.csv") #insert the  raw URL for the data file on github here
traitstemp<- read.csv(text = raw) #read in the github file
traitstemp$Value<-sapply(traitstemp$Value, as.character)
traitstemp$Value<-sapply(traitstemp$Value, as.numeric)
```

Turn the traits list into a matrix, put  n/a for species/trait cells that do not have data
```{r}
require(reshape)
traitmatrix<-cast(traitstemp, Trait ~ Species, value='Value', fun.aggregate=mean)
```

to view the full dataset
```{r}
utils::View(comm)
```

export the traits list and community cover lists to Excel, since they have some mismatches in species content

oh - probably because it contains all species and the community list just contains herbaceous species at the moment because that is the only group of plants with cover estimates - so we're exporting to make a list with just herbaceous species.  Additionally the full traits list requested all species observed in 2012 intensive sampling and 2013 extensive sampling; not all 2013 species were observed in 2012, and those are removed from the truncated list as well
n.b. acer saccharum is still in both lists, seedlings had cover estimates

will need to rename Athyrium filix-femina var. angustum in comm data to Athyrium filix-femina to match trait data
same for Circaea lutetiana ssp. canadensis -> Circaea lutetiana
Maianthemum racemosum ssp. racemosum -> Maianthemum racemosum
also need to remove anything Genus sp. from comm list, and all the SP##
fix typo in comm, Hyperium mutilum to Hypericum mutilum

```{r}
write.table(traitmatrix, file="TRY_traitsmatrix.csv", sep=",", row.names=F)
write.table(comm_cover, file="2012_comm_cover.csv", sep=",", row.names=F)
```


reimport the data edited as above
```{r}
#community
comm2012<-read.csv("2012_comm_cover_herbs.csv")
rownames(comm2012)<-comm2012$Site
comm2012<-comm2012[,2:166]

#traits
traits2012<-read.csv("2012_TRY_traitsmatrix_herbs.csv")
rownames(traits2012)<-traits2012$Trait
traits2012<-traits2012[,2:166]

```


editing the dissimilarity matrix in excel: if a species has 5 or fewer missing distances, interpolate.  more than 5, remove species from analysis.

removed species (n=34):

Carex bullata
Didiplis.diandra
Dryopteris.camyloptera
Dryopteris.marginalis
Echinochloa.muricata
Eurybia.divaricata  
Eutrochium.purpureum
Halenia.deflexa
Hydrocotyle.americana
Hylotelephium.telephium
Lactuca.canadensis
Muhlenbergia.sobolifera
Oxalis.grandis
Paspalum.setaceum
Polygonum.arifolium
Polygonum.cespitosum
Polystichum.acrostichoides  
Potentilla.simplex
Rubus.pubescens
Rumex.triangulivalvis 
Sanicula.odorata
Scirpus.polyphyllus
Sinapis.arvensis
Smilax.glauca
Solanum.ptycanthum
Stellaria.pubera
Symphyotrichum.dumosum
Symphyotrichum.lateriflorum
Teucrium.canadense
Thalictrum.thalictroides
Trifolium.arvense 
Trifolium.campestre
Viola.fimbriatula
Viola.pubescens

```{r}
trim_trait_dis<-read.csv("2012_trait_dissimilarity_trim_averaged_NAs.csv")
rownames(trim_trait_dis)<-trim_trait_dis$X
trim_trait_dis<-trim_trait_dis[,2:132]
trim_trait_dis<-as.matrix(trim_trait_dis)
fit<-isoMDS(trim_trait_dis, k=2)
fit
x<-fit$points[,1]
y<-fit$points[,2]
plot(x,y)
```

rownames(traits2012)<-traits2012$Trait
traits2012<-traits2012[,2:132]


Make a trait dissimilarity matrix for the species
```{r}
require(cluster)
traitdiss<-daisy(traits2012trans2, metric = "euclidean")
traitdissim<-as.matrix(traitdiss)

#try FD again with trait dissim? - no, it won't allow NAs with that
#do I want gower or a different dissimilarity?

I think I can work with this dissimilarity matrix or another one and make decisions about interpolating NAs or deleting certain species or traits

write.table(traitdissim, file="2012_trait_dissimilarity.csv", sep=",", row.names=T)


```


It might be best to try the method as outlined in the proposal first using just a handful of traits, by hand, and then extend to the larger dataset at a later date.  Check - which traits show the most variation?  plot histograms

The partitioning of variation in trait states will work better with the qualitative traits, stick with those for the stuff by hand.  


Need to create a matrix with trait abundance values (site by trait, derived from site by species).  Potentially follow method in Ackerly and Cornwell 2007?

fill a new matrix - for each community, make columns for each trait, average trait values for each species in the community

would a species by trait matrix help?


Trying a new method RLQ following https://climateecology.wordpress.com/2013/09/03/r-for-ecologists-rlq-analysis-semi-explained/ (this will be great to transfer into the extensive sampling analysis as well, if it works with presence/absence; in the meantime just borrowing some info).  ok maybe not so helpful here

