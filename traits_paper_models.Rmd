---
title: "Analyses for 'The role of functional plant traits in determining vegetation distribution patterns in riparian landscapes"
author: "Emily J. Rollinson"
date: "Friday, January 30, 2015"
output: html_document
---

Import the community species abundance dataset by cover

```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/2012_cover_allsp.csv") #insert the  raw URL for the data file on github here
tempcover<- read.csv(text = raw) #read in the github file
```

Make a species cover matrix
```{r}
require(reshape)
tempcover<-cast(tempcover, Code ~ Species, value="Cover", fun.aggregate=sum)
tempcover<-as.data.frame(tempcover)
```

Make a copy of the cover matrix and reframe so that the site names are row names and not a column
```{r}
cover<-tempcover
rownames(cover)<-cover$Code
cover<-cover[,2:182]
```

Import the traits matrix and make sure all values are numeric

```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/TRY_traitsmatrix_quant_only2012sp_interpseedmass_absval.csv") #insert the  raw URL for the data file on github here
traits<- read.csv(text = raw, check.names = FALSE, row.names=1) #read in the github file
```

playing with the FD functional diversity package - species have to be columns in the community dataset and rows in the traits dataset

```{r}
require(FD)
#transpose the traits matrix
traits_tp<-t(traits)
traits_tp<-as.data.frame(traits_tp)

pref_traits<-traits_tp[,c(6,9:11,21,26:28,33,36,38,42,43,46,47)]#making a smaller list of traits of particular interest

newpreftraits<-traits_tp[,c(8,9,13,16,20,21,23,26,27,28,29, 35,39,43,44,46,47,48,54,55,56)]

```

6:leaf area
9: leaf C/N
10: leaf density
11:leaf dry mass
21: leaf N/P
26: K per dry mass
27: SLA
28: leaf thickness
33: photosynthesis per leaf area
36 plant height vegetative
38 plant relative growth rate
42 root N per dry mass
43 root depth
46 seed mass
47 seed number per reproduction unit

pref_traits: 181 x 15 traits are columns
cover: 24 x 181 species are columns


Redo this with the preferred traits use in native v. introduced?
8 leaf C per dry mass
9 leaf C to N ratio
13 leaf weight ratio
16 lamina thickness
20 leaf N per dry mass
21 leaf N to P ratio
23 leaf P per dry mass
leaf physical strength (n/a, sub in #29 leaf thickness)
26 leaf K per dry mass
27 leaf respiration per dry mass
28 SLA
35 photosynthesis per leaf dry mass
39 RGR
43 root N per dry mass
44 rooting depth
46 seed mass
47 seed no per repro unit
48 seed protein content per mass
54 SSD
55 stomata conductance per leaf area
56 wood dry mass per plant dry mass

with original preferred traits
```{r}
FD<-dbFD(pref_traits, cover, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE) #this is what worked

export = FD[1:8]
test<-as.data.frame(export)
write.table(test, "functionaldiv2012.csv", sep=",", col.names=NA, row.names=TRUE)

export2 = FD[2]
test2<-as.data.frame(export2)

CWM2<-FD$CWM

CWM2$type<-c("g","g","u","u","g","g","u","u","g","g","u","u","g","g","u","u","g","g","u","u","g","g","u","u")
CWM2<-CWM2[order(CWM2$type),]

#need to standardize each column - no, gower does this automatically

CWM3<-CWM2[,1:21]

#rough interpolation to allow ordination to proceed  - give any NA the median value for that column
fx=function(x){
  x[is.na(x)]=median(x, na.rm=TRUE)
  x
}
CWM3=data.frame(apply(CWM3,2,fx))

#don't use the scaled one, none of the distances in vegan like negative values

require(vegan)
ordslope<-metaMDS(CWM3, dist="gower") #gower scales each column to unit range

type=c(rep("GL", 12), rep("UP", 12))
ordiplot(ordslope, type="n", xlim=(c(-.5,1)), ylim=(c(-.5,1)))
#ordihull(ord, groups=type, draw="polygon", col="grey90", label=F) #for tightest convex hull containing all points in the group
ordiellipse(ordslope, groups=type, draw="lines", kind="sd", col="black", label=T) #for ellipse representing SD of community

points(ordslope, display="sites", col=c(rep("red", 12), rep("blue", 12)), pch= 19)

orditorp(ordslope, display="species", col="black", pch=8) #this will plot the traits ("species" in vegan package lingo which always means whatever your columns are)

anosim(CWM3, type, distance="gower")

slopeNMDSpts<-ordslope$points

```

with new preferred traits
```{r}
FD<-dbFD(newpreftraits, cover, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE) #this is what worked

export = FD[1:8]
test<-as.data.frame(export)
write.table(test, "functionaldiv2012_newtraits.csv", sep=",") #new traits uses the same traits as in the native vs. introduced work

export2 = FD[2]
test2<-as.data.frame(export2)

CWM<-FD$CWM

CWM$type<-c("g","g","u","u","g","g","u","u","g","g","u","u","g","g","u","u","g","g","u","u","g","g","u","u")

#write.table(CWM, "2012CWMtemp.csv", sep=",") exported to sort because every option of sorting in R was breaking things
#reimport sorted by bank type

CWM2<-read.csv("2012CWMtemp.csv")
row.names(CWM2)<-CWM2$X
CWM2<-CWM2[,2:16]

#need to standardize each column

CWM2scaled<-as.data.frame(scale(CWM2))

#rough interpolation to allow ordination to proceed  - give any NA the median value for that column
fx=function(x){
  x[is.na(x)]=median(x, na.rm=TRUE)
  x
}
CWM2=data.frame(apply(CWM2,2,fx))

#don't use the scaled one, none of the distances in vegan like negative values

require(vegan)
ordslope<-metaMDS(CWM2, dist="gower") #gower scales each column to unit range

type=c(rep("GL", 12), rep("UP", 12))
ordiplot(ordslope, type="n")
#ordihull(ord, groups=type, draw="polygon", col="grey90", label=F) #for tightest convex hull containing all points in the group
ordiellipse(ordslope, groups=type, draw="lines", kind="sd", col="black", label=T) #for ellipse representing SD of community

points(ordslope, display="sites", col=c(rep("red", 12), rep("blue", 12)), pch= 19)

orditorp(ordslope, display="species", col="black", pch=8) #this will plot the traits ("species" in vegan package lingo which always means whatever your columns are)

anosim(CWM2, type)

```




reimport sites by traits
```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/site_by_trait_matrix_interp.csv") #insert the  raw URL for the data file on github here
sitebytrait<- read.csv(text = raw) #read in the github file
rownames(sitebytrait)<-sitebytrait$Site
sitebytrait<-sitebytrait[,2:57]
prcomp(sitebytrait)
```

ordinate PCA
```{r}

#remove traits with NAs
# column 17 has an NA
sitebytrait_noNA<-sitebytrait[,c(1:16,18:56)]

library(vegan)
ord <- metaMDS(sitebytrait_noNA, distance = "gower", k=2, trymax=50)
plot(ord)

#plot the ordination without traits showing, and with sites shown in text (this package is meant for sites/species so i am calling traits "species"")
#vegan interprets rows and columns as sites and species automatically, so you can just type "sites" or "species" for what you want to plot - you don't have to define those
#cex varies the text size

plot(ord, type="n")
text(ord, display ="sites", cex =0.7)

#plot to look at the sites with the traits names superimposed
plot(ord)
text(ord, display="species", cex=0.7)

```

reimport Fdiversity values as a table
```{r}
require(lme4) #for GLMs
require(arm) #for display()
traitsdiv<-read.csv("FD.csv", check.names=TRUE) #oops i have two columns named as site; I can fix that (the first should be row.names) but for now just used the renamed Site.1 in the model

#Functional richness #something is wrong with the Fric values - recalculate and reimport.  it's meant to vary between 0 and 1 (therefore should be binomial).  higher is richer.  Oh they are all wrong - the whole thing shifted the column names one left of where they should be
Fric0<-glm(FRic ~ 1, family="quasipoisson", offset=log(Area), data=traitsdiv)
Fric1<-glm(FRic ~ River, family ="quasipoisson", offset=log(Area), data=traitsdiv)
Fric2<-glm(FRic ~ River/Site.1, family="quasipoisson", offset=log(Area), data=traitsdiv)
Fric3<-glm(FRic ~ River/Site.1/Bank, family="quasipoisson", offset=log(Area), data=traitsdiv)
display(Fric0)
display(Fric1)
display(Fric2)
display(Fric3)
anova(Fric0,Fric1,Fric2,Fric3, test="Chisq")
summary(Fric3)

model.matrix(Fric3) #use this on the model of interest (rich1, rich2, etc - to look at all the comparisons in the model matrix and confirm what contrasts go with which somewhat-obscure name in the summary)

#Functional evenness
FEve0<-glm(FEve ~ 1, family="quasipoisson", offset=log(Area), data=traitsdiv)
FEve1<-glm(FEve ~ River, family ="quasipoisson", offset=log(Area), data=traitsdiv)
FEve2<-glm(FEve ~ River/Site.1, family="quasipoisson", offset=log(Area), data=traitsdiv)
FEve3<-glm(FEve ~ River/Site.1/Bank, family="quasipoisson", offset=log(Area), data=traitsdiv)
display(FEve0)
display(FEve1)
display(FEve2)
display(FEve3)
anova(FEve0,FEve1,FEve2,FEve3, test="Chisq")
summary(FEve3)

#Functional diversity
FDiv0<-glm(FDiv ~ 1, family="quasipoisson", offset=log(Area), data=traitsdiv)
FDiv1<-glm(FDiv ~ River, family ="quasipoisson", offset=log(Area), data=traitsdiv)
FDiv2<-glm(FDiv ~ River/Site.1, family="quasipoisson", offset=log(Area), data=traitsdiv)
FDiv3<-glm(FDiv ~ River/Site.1/Bank, family="quasipoisson", offset=log(Area), data=traitsdiv)
display(FDiv0)
display(FDiv1)
display(FDiv2)
display(FDiv3)
anova(FDiv0,FDiv1,FDiv2,FDiv3, test="Chisq")
summary(FDiv3)


#RaoQ - varies between zero and 1 - should use binomial?
RaoQ0<-glm(RaoQ ~ 1, family="quasibinomial", offset=log(Area), data=traitsdiv)
RaoQ1<-glm(RaoQ ~ River, family ="quasibinomial", offset=log(Area), data=traitsdiv)
RaoQ2<-glm(RaoQ ~ River/Site.1, family="quasibinomial", offset=log(Area), data=traitsdiv)
RaoQ3<-glm(RaoQ ~ River/Site.1/Bank, family="quasibinomial", offset=log(Area), data=traitsdiv)
display(RaoQ0)
display(RaoQ1)
display(RaoQ2)
display(RaoQ3)
anova(RaoQ0,RaoQ1,RaoQ2,RaoQ3, test="Chisq")
summary(RaoQ3)


```

The most basic possible plot to look at all the points for greenline versus upslope, for whichever variable in "data" is desired:
```{r}
require(ggplot2)
qplot(data=traitsdiv, y=FDiv, x=Bank, geom("point"))

```

------------------------------------------------------------------------------------
*Riparian vs. upslope communities*

```{r}
#read in 2012 abundances
intensivelist<-read.csv("2012_abundancematrix_withgroupings.csv")
intensivelist<-intensivelist[order(intensivelist$elev),]

#separate into greenline and upslope communities
gl<-intensivelist[c(1,2,5,6,9,10,13,14,17,18,21,22),]
up<-intensivelist[c(3,4,7,8,11,12,15,16,19,20,23,24),]

#wait is this necessary, don't i have a distance matrix for 2012

```
------------------------------------------------------------------------------------
*Native vs. introduced portions of the community*

```{r}
fulllist<-read.csv("2013_speciespresences_by_origin.csv", check.names=FALSE)

invs<-fulllist[1:308,1:3] #subset of the complete species list that are known introduced
nats<-fulllist[309:1511, 1:3] #subset of the complete species list that are known native

#omits species with unresolved origin status entirely (n=7 species; 34 observations)

require(reshape)
tempinvs<-cast(invs, River ~ Species, value="Presence", fun.aggregate=mean)
row.names(tempinvs)<-tempinvs$River
tempinvs2<-tempinvs[,2:62]
tempinvs3<-rapply(tempinvs2, f=function(x) ifelse(is.nan(x),0,x), how="replace")
tempinvs3<-as.data.frame(tempinvs3, check.names=FALSE)
row.names(tempinvs3)<-tempinvs$River
invcomm<-tempinvs3

tempnats<-cast(nats, River~Species, value="Presence", fun.aggregate=mean)
row.names(tempnats)<-tempnats$River
tempnats2<-tempnats[,2:213]
tempnats3<-rapply(tempnats2, f=function(x) ifelse(is.nan(x),0,x), how="replace")
tempnats3<-as.data.frame(tempnats3)
row.names(tempnats3)<-tempnats$River
natcomm<-tempnats3


#import traits matrices for inv and nat 2013 species

invtraits<-read.csv("2013_traits_invs.csv")
nattraits<-read.csv("2013_traits_natives.csv")

row.names(invtraits)<-invtraits$Trait
invtraits2<-invtraits[,2:61]

row.names(nattraits)<-nattraits$Trait
nattraits2<-nattraits[,2:189]

alltraits<-merge(invtraits, nattraits)

#transpose for FD 
tinvtraits<-t(invtraits2)
tinvtraits<-as.data.frame(tinvtraits)
tnattraits<-t(nattraits2)
tnattraits<-as.data.frame(tnattraits)
```
community matrix has an error invcomm contains Cynanchum louiseae and traits matrix does not.  Remove from invcomm it is column 12

same error for natives, many in community list but no traits

25 brachyelytrum aristosum
43 cornus obliqua
51 doellengeria umbellata
55 elymus canadensis
67 eurybia divaricata
68 euthamia caroliniana
70 eutrochium maculatum
71 euthrochium purpureum
82 gentiana linearis
86 helianthus divaricatus
89 heuchera villosa
118 oclemena acuminata
135 polygonum arifolium
136 polygonum cilinode
145 prenanthes altissima
146 prenanthes trifoliata
153 quercus prenoides
175 smilax tamnoides
180 solidago latissimifolia
182 stellaria pubera
183 symphyotrichum dumosum
185 symphyotrichum novae.angleae
190 thalictrum thalictroides
196 triadenum virginicum
211 woodsia obtusa

```{r}
invcomm2<-invcomm[,c(1:11,13:61)]

natcomm2<-natcomm[,c(1:24,26:42, 44:50, 52:54,56:66,69,72:81,83:85,87,88,90:117, 119:134, 137:144, 147:152,154:174,176:179,181,184,186:189,191:195,197:210,212)]

#export these to categorize them as woody or herbaceous
#write.table(invcomm2, "tempinvasivecomm13.csv", sep=",")
#write.table(natcomm2, "tempnativecomm13.csv", sep=",")

#pref_traits: 181 x 15 traits are columns
#cover: 24 x 181 species are columns

#tnattraits: 188 x 76, traits are columns
#natcomm2: 53 x 188, species are columns

#tinvtraits 60 x 76, traits are columns
#invcomm2: 53 x 60, species are columns
#distance matrix?

#FDnat<-dbFD(tinvtraits, invcomm2, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE)
#FDinv<-dbFD(tnattraits, natcomm2, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE )

#ok, need to do the same export-and-interpolate for the traits matrix as I did for the first FD
#seed mass was missing for 2 species, gave it the median (inv traits)
#seed mass missing for 29 species, give them the median (nat traits)

write.table(tnattraits, "2013nativetraits.csv", sep=",")
write.table(tinvtraits, "2013invtraits.csv", sep=",")

#needed to delete eleocharis intermedia from traits before reimporting, it wasn't in comm data (native species)

#reimport traits data

invtrt<-read.csv("2013invtraits_interp.csv")
row.names(invtrt)<-invtrt$X
invtrt<-invtrt[,2:63]

nattrt<-read.csv("2013nativetraits_interp.csv")
row.names(nattrt)<-nattrt$X
nattrt<-nattrt[,2:66]

#i think i need to try resaving these csvs with everything set to numeric in excel, delete the totally NA traits (no data for any species in the subset), deleting the extra rows
#the same traits should also be used for native and invasive distance matrices, so once these are reimported as edited above,  make preferred-trait subsets that have matching traits

#require(FD)
#FDinv<-dbFD(invtrt, invcomm2, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE)
#FDnat<-dbFD(nattrt, natcomm2, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE )


#throwing an error  Species labels in 'x' and 'a' need to be identical and ordered alphabetically (or simply in the same order). for natives; invasives are working.  export nattrt and natcomm2 to check quickly in excel.  The issue is misspelling = "Oenothera biennis" in the traits file and Oenethera biennis in the community file.  Oenothera is the correct spelling; change the name of that column in the community file.  

#write.table(nattrt, "testfile_nativetraits.csv", sep=",", row.names=TRUE)
#write.table(natcomm2, "testfile_nativecomm.csv", sep=",", row.names=TRUE)
#can delete those tables now

names(natcomm2)[names(natcomm2)=="Oenethera.biennis"] <- "Oenothera.biennis"

rownames(invtrt)<-colnames(invcomm2)
rownames(nattrt)<-colnames(natcomm2)

require(FD)
FDinv<-dbFD(invtrt, invcomm2, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE)
FDnat<-dbFD(nattrt, natcomm2, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE)

#export $CWM from this to get the traits matrix to then marge back together and compare community distances.
#for future reference 'functcomp' returns the community level weighted means, don't have to run all other things in 'dbFD'

inv_sitebytrait<-FDinv$CWM
nat_sitebytrait<-FDnat$CWM

#write these to tables so i have them saved in case the code magically dies
write.table(inv_sitebytrait, "sitebytraitmatrix_inv2013.csv", sep=",", row.names=TRUE, col.names=TRUE)
write.table(nat_sitebytrait, "sitebytraitmatrix_nat2013.csv", sep=",", row.names=TRUE, col.names=TRUE)

#reimport the site by trait matrix that has been pruned to shared/preferred traits and lists communities separately as invasive and native portions of each site.

partcomm<-read.csv("2013_sitebytraitmatrix_partitionedbyorigin.csv")
row.names(partcomm)<-partcomm$Comm
partcomm<-partcomm[,3:23]

#rough interpolation to allow ordination to proceed  - give any NA the median value for that column
fx=function(x){
  x[is.na(x)]=median(x, na.rm=TRUE)
  x
}
int_partcomm=data.frame(apply(partcomm,2,fx))


#Ordinate that matrix

require(vegan)
ord<-metaMDS(int_partcomm, distance="gower", noshare=FALSE, zerodist="add", k=3)
ordiplot(ord, type="n", xlim=c(-0.3,0.5), ylim=c(-0.3, 0.5))
type=c(rep("Introduced", 53), rep("Native", 53))
#ordihull(ord, groups=type, draw="polygon", col="grey90", label=F) #for tightest convex hull containing all points in the group
ordiellipse(ord, groups=type, draw="lines", kind="sd", col="black", label=T) #for ellipse representing SD of community

points(ord, display="sites", col=c(rep("red", 53), rep("blue", 53)), pch= 19)

orditorp(ord, display="species", col="black", pch=8) #this will plot the traits ("species" in vegan package lingo which always means whatever your columns are)


#test significance
anosim(int_partcomm, type, distance="gower")

#look at pairwise differences
diff<-as.matrix(vegdist(int_partcomm, method ="gower")) 
diffni<-diff[1:53,54:ncol(diff)]
diffni2<-diag(diffni)
hist(diffni2, breaks=20)
lines(density(diffni2), lwd=2)
mean(diffni2)

#try a PCA

require(ape)
allpca<-pcoa(diff, correction="cailliez")
biplot(allpca, xlabs=rep("", 106))

```


Example code to get a biplot with points  #this isn't working, it plots text with points, but i could use that to tailor by hand in illustrator... 

fit<-princomp(some.data, cor=T) 

biplot(fit, xlabs=rep("", no.of.poins)) #biplot without points 

#some scaling of plot parameters 

rrr<-apply(fit$scores[,1:2],2, range) 
(abs(rrr)+.1)*sign(rrr) 
par(usr=as.vector(rrr)) 

# plot the points according to some leves 
points(fit$scores[,1:2], 
col=jet.colors(11)[(as.numeric(kvalita.ag$typ[cc]))], pch=20) 



-----------------------------


Native vs. introduced - herbs only and woody only.
Need to prune the partitioned community into a herbaceous-only version and a woody-only version - this set of code didn't work, skip to next section

```{r}
natwood<-read.csv("2013_TRY_traitsmatrix_nativewoody.csv")
intwood<-read.csv("2013_TRY_traitsmatrix_introducedwoody.csv")
natherb<-read.csv("2013_TRY_traitsmatrix_nativeherbs.csv")
intherb<-read.csv("2013_TRY_traitsmatrix_introducedherbs.csv")

hpartcomm<-read.csv("2013_speciespresences_by_origin_sitenamepartitioned_herbsonly.csv")
wpartcomm<-read.csv("2013_speciespresences_by_origin_sitenamepartitioned_woodyonly.csv")


#make p/a matrices for woody and herbaceous communities (partitioned by origin)

require(reshape)

hp1<-cast(hpartcomm, PartSite ~ Species, value="Presence", fun.aggregate=mean)
row.names(hp1)<-hp1$PartSite
hp2<-hp1[,2:203]
hp3<-rapply(hp2, f=function(x) ifelse(is.nan(x),0,x), how="replace")
hp3<-as.data.frame(hp3, check.names=FALSE)
row.names(hp3)<-hp1$PartSite


wp1<-cast(wpartcomm, PartSite ~ Species, value="Presence", fun.aggregate=mean)
row.names(wp1)<-wp1$PartSite
wp2<-wp1[,2:72]
wp3<-rapply(wp2, f=function(x) ifelse(is.nan(x), 0, x), how="replace")
wp3<-as.data.frame(wp3, check.names=FALSE)
row.names(wp3)<-wp1$PartSite

#make woody and herbaceous trait matrices
wtraits<-merge(natwood,intwood)
row.names(wtraits)<-wtraits$Trait
wtraits<-wtraits[,2:66]
wtraits<-wtraits[order(row.names(wtraits)),]


htraits<-merge(natherb, intherb)

#transpose traits matrices for FD
wtraitst<-as.data.frame(t(wtraits))
wtraitst<-wtraitst[order(row.names(wtraitst)),]


#get the CWM for woody and herbaceous parts of the already-partitioned-by-origin communities

#traits 65 species x 76 traits
#comm 91 sites x 71 species

#^there are probably species in the community list of ambiguous origin that need removing
#in wp3, remove:
#18 cornus obliqua
#28 helianthus divaricatus
#35 oclemena acuminata
#45 quercus prinoides
#62 stellaria pubera
#63 symphotrichum dumosum

wp3<-wp3[,c(1:17,19:27,29:34,36:44, 46:61, 64:71)]
#and then the oenethera/oenothera spelling problem again
names(wp3)[names(wp3)=="Oenethera.biennis"] <- "Oenothera.biennis"

#seed mass is 62, missing for row 53 rubus phoenicolasus
wtraitst[53,62]<-median(wtraitst[c(1:52,54:nrow(wtraitst)),62])  #this puts the median seed mass value in for the one missing seed mass value


require(FD)
hFD<-dbFD(wtraitst, wp3, stand.x=TRUE, ord="podani", corr = "cailliez")
#traits: traits are columns 65 species, 76 traits
#p/a: species are columns 91 "sites", 65 species

#confusingly this is still throwing an error so let's interpolate everything for now and return to the issue later

#fx=function(x){
#  x[is.na(x)]=median(x, na.rm=TRUE)
#  x
#}
#iwtraitst=data.frame(apply(wtraitst,2,fx))

#nope, that still throws an error.  are there totally missing species causing a problem?  no, all species have at least one presence

#can i go to the original working code and just separate out the herbs and woody from the working invasive/native matrices? 

```


This is the attempt at native vs. introduced that worked
```{r}

#try again reading in different datasets

#TRAITS
natwoodt<-read.csv("2013nativetraits_interp_wood_preftraits.csv", row.names=1)
intwoodt<-read.csv("2013invtraits_interp_wood_preftraits.csv", row.names=1)
natherbt<-read.csv("2013nativetraits_interp_herbs_preftraits.csv", row.names=1)
intherbt<-read.csv("2013invtraits_interp_herbs_preftraits.csv", row.names=1)

#COMMUNITIES
natwoodc<-read.csv("nativewood13.csv", row.names=1)
intwoodc<-read.csv("intwood13_noempty.csv", row.names=1)
natherbc<-read.csv("nativeherbs13.csv", row.names=1)
intherbc<-read.csv("intherbs13_noempty.csv", row.names=1)

#transpose the traits matrices for FD, which requires species as rows and traits as columns
#outdated, current data frames imported already in correct format
#tnatwoodt<-as.data.frame(t(natwoodt))
#tintwoodt<-as.data.frame(t(intwoodt))
#tnatherbt<-as.data.frame(t(natherbt))
#tintherbt<-as.data.frame(t(intherbt))

#fixing minor errors/mismatches
###problem with native herbs - typos in names causing mismatch
names(natherbc)[names(natherbc)=="athyrium_filix.femina"] <- "athyrium_filix_femina"
names(natherbc)[names(natherbc)=="veronica_anagallis.aquatica"] <- "veronica_anagallis_aquatica"
###problem with invasive wood - completely NA traits (cols 10, 14, 21) need to be removed
intwoodt2<-intwoodt[,c(1:9,11:13,15:20)]

require(FD)
nwFD<-dbFD(natwoodt, natwoodc, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE) #works
#so the issue is that it doesn't like a traits column that is entirely NAs
nhFD<-dbFD(natherbt, natherbc, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE) #works
iwFD<-dbFD(intwoodt2, intwoodc, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE) #works
ihFD<-dbFD(intherbt, intherbc, stand.x=TRUE, ord="podani", corr = "cailliez", w.abun=TRUE, stand.FRic=TRUE) #works

#export all the CWMs before the code stops working

write.table(nwFD$CWM, "nwCWM.csv", sep=",", col.names=NA, row.names=TRUE)
write.table(nhFD$CWM, "nhCWM.csv", sep=",", col.names=NA, row.names=TRUE)
write.table(iwFD$CWM, "iwCWM.csv", sep=",", col.names=NA, row.names=TRUE)
write.table(ihFD$CWM, "ihCWM.csv", sep=",", col.names=NA, row.names=TRUE)

#merge the native and introduced bits for herbs, and separately for woody,  reimport the site by trait matrices, listing communities separately as introduced and native portions of each site.  

wpcomm<-read.csv("woodCWM_partbyorigin.csv", row.names=1)
hpcomm<-read.csv("herbsCWM_partbyorigin.csv", row.names=1)


#rough interpolations to allow ordination to proceed  - give any NA the median value for that column
fx=function(x){
  x[is.na(x)]=median(x, na.rm=TRUE)
  x
}

iwpcomm=data.frame(apply(wpcomm,2,fx))
ihpcomm=data.frame(apply(hpcomm,2,fx))

#Ordinate those matrices

###woody

require(vegan)
word<-metaMDS(iwpcomm, distance="gower", noshare=FALSE, zerodist="add", k=3)
ordiplot(word, type="n")
wtype=c(rep("Native", 53), rep("Introduced", 38))
#ordihull(ord, groups=type, draw="polygon", col="grey90", label=F) #for tightest convex hull containing all points in the group
ordiellipse(word, groups=wtype, draw="lines", kind="sd", col="black", label=T) #for ellipse representing SD of community

points(word, display="sites", col=c(rep("blue", 53), rep("red", 38)), pch= 19)

orditorp(ord, display="species", col="black", pch=8) #this will plot the traits ("species" in vegan package lingo which always means whatever your columns are)

##herbs
hord<-metaMDS(ihpcomm, distance="gower", noshare=FALSE, zerodist="add", k=3)
ordiplot(hord, type="n")
htype=c(rep("Introduced", 50), rep("Native", 53))
#ordihull(ord, groups=type, draw="polygon", col="grey90", label=F) #for tightest convex hull containing all points in the group
ordiellipse(hord, groups=htype, draw="lines", kind="sd", col="black", label=T) #for ellipse representing SD of community

points(hord, display="sites", col=c(rep("red", 50), rep("blue", 53)), pch= 19)

orditorp(ord, display="species", col="black", pch=8) #this will plot the traits ("species" in vegan package lingo which always means whatever your columns are)

#test significance
anosim(iwpcomm, wtype, distance="gower")
anosim(ihpcomm, htype, distance="gower")

#get the dissimilarities to look at them pairwise within each community
wooddist<-as.matrix(vegdist(iwpcomm, method ="gower"))   #use this and make a histogram of average distances between the native and introduced bits of each community
herbdist<-as.matrix(vegdist(ihpcomm, method="gower"))

##look at the average dissimilarities
###woody
wdiff<-wooddist[1:53,54:91]
#then remove the missing introduced communities (5,6,7,12,13,19,23,25,36,37,41,44,47,50,52)
wdiff2<-wdiff[c(1:4,8:11,14:18,20:22,24,26:35,38:40,42,43,45,46,48,48,51,53),]
wdiff3<-diag(wdiff2)
hist(wdiff3, breaks=22)
mean(wdiff3)

#herbaceous
hdiff<-herbdist[1:50,51:103]
#then remove the missing introduced communities (10,22,39)
hdiff2<-hdiff[,c(1:9,11:21,23:38,40:ncol(hdiff))]
hdiff3<-diag(hdiff2)
hist(hdiff3, breaks=20)
mean(hdiff3)

#what do all pairwise distances look like?

hist(wdiff2)
mean(wdiff2)
hist(hdiff2)
mean(hdiff2)

```


introduced woody - removing empty communities
big brook
boreas river
bullhead pond brook
daly creek
evas kill
hudson river
kayaderosseras creek
keyser kill
plotter kill
potic creek
saw kill
sprout creek
stewart creek
trout brook
wappinger creek

introduced herbs - removing empty communities
chester creek
jassup river
robbs creek

native herbs - formatting mismatch for athyrium filix-femina

Attempting a PCA to display some of the traits...

```{r}
require(ape)
require(vegan)

#get the dissimilarities to look at them pairwise within each community
wooddist<-as.matrix(vegdist(iwpcomm, method ="gower"))   #use this and make a histogram of average distances between the native and introduced bits of each community
herbdist<-as.matrix(vegdist(ihpcomm, method="gower"))

wpctest<-pcoa(wooddist, correction="cailliez")
biplot(wpctest, Y=iwpcomm)

hpctest<-pcoa(herbdist, correction="cailliez")
biplot(hpctest, Y=ihpcomm)

#this makes a hot mess graphically

```


What is the average dissimilarity among communities generally?
Need a CWM for all the 2013 species
```{r}
sites<-read.csv("2013_species_presence_list_for_traits.csv")
require(reshape)
tempsites<-cast(sites, River ~ Species, value ="Presence", fun.aggregate=mean)
row.names(tempsites)<-tempsites$River
tempsites2<-tempsites[,2:ncol(tempsites)]
tempsites3<-as.data.frame(rapply(tempsites2, f=function(x) ifelse(is.nan(x),0,x), how="replace"))
rownames(tempsites3)<-tempsites$River
comm<-tempsites3

traits<-read.csv("2013_TRY_traitsmatrix.csv", row.names=1)

ttraits<-t(traits)

#mismatch between the two at row 71 - traits lists eleocharis intermedia and community lists elymus canadensis.  delete both.

ttraits<-ttraits[c(1:70,72:nrow(ttraits)),]
comm<-comm[,c(1:70,72:ncol(comm))]

require(FD)
allFD<-dbFD(ttraits, comm)

#need to revisit this.  use the preferred traits only and remove any N/I partitioning.  investigate the eleocharis/elymus problem.
```



plotting a PCA plotting code from http://stackoverflow.com/questions/6578355/plotting-pca-biplot-with-ggplot2
```{r}

#look at the above again as a PCA so i can put biplot arrows in?

require(ade4)
pcatest<-dudi.pca(int_partcomm)
pcatest2<-prcomp(int_partcomm, scale=TRUE)
plot(pcatest2)
biplot(pcatest2)

PCbiplot <- function(PC, x="PC1", y="PC2") {
    # PC being a prcomp object
    data <- data.frame(obsnames=row.names(PC$x), PC$x)
    plot <- ggplot(data, aes_string(x=x, y=y)) + geom_text(alpha=.4, size=3, aes(label=obsnames))
    plot <- plot + geom_hline(aes(0), size=.2) + geom_vline(aes(0), size=.2)
    datapc <- data.frame(varnames=rownames(PC$rotation), PC$rotation)
    mult <- min(
        (max(data[,y]) - min(data[,y])/(max(datapc[,y])-min(datapc[,y]))),
        (max(data[,x]) - min(data[,x])/(max(datapc[,x])-min(datapc[,x])))
        )
    datapc <- transform(datapc,
            v1 = .7 * mult * (get(x)),
            v2 = .7 * mult * (get(y))
            )
    plot <- plot + coord_equal() + geom_text(data=datapc, aes(x=v1, y=v2, label=varnames), size = 5, vjust=1, color="red")
    plot <- plot + geom_segment(data=datapc, aes(x=0, y=0, xend=v1, yend=v2), arrow=arrow(length=unit(0.2,"cm")), alpha=0.75, color="red")
    plot
}

fit <- prcomp(USArrests, scale=T)
PCbiplot(fit)



```

plotting some of the inv versus native traits - first try without interpolated values
```{r}
invtraits<-read.csv("2013_traits_invs.csv")
nattraits<-read.csv("2013_traits_natives.csv")

row.names(invtraits)<-invtraits$Trait
invtraits2<-invtraits[,2:61]

row.names(nattraits)<-nattraits$Trait
nattraits2<-nattraits[,2:189]

tinvtraits2<-as.data.frame(t(invtraits2))
tnattraits2<-as.data.frame(t(nattraits2))
tinvtraits2$Origin<-"I"
tnattraits2$Origin<-"N"

alltraits2<-rbind(tinvtraits2, tnattraits2)

require(ggplot2)

require(plyr)

#plot seed mass
names(alltraits2)[names(alltraits2)=="Seed mass"] <-"Seedmass" #ddply doesn't seem to like spaces in column names, or ""ing them

cseed<-ddply(alltraits2, c("Origin"), summarise,
             N = sum(!is.na(Seedmass)),
             mean = mean(Seedmass, na.rm=TRUE),
             sd = sd(Seedmass, na.rm=TRUE),
             se = sd/sqrt(N))

#require(bear)
#dfseed<-summarySE(alltraits2, measurevar="Leaf dry mass", groupvars=c("Origin"))

ggplot(cseed, aes(x=Origin, y=mean)) + geom_bar(position=position_dodge(), stat="identity") + geom_errorbar(aes(ymin=mean-se, ymax = mean+se), width=.2) + ggtitle("Seed Mass")


#plot SSD

names(alltraits2)[names(alltraits2)=="Stem specific density (SSD)"] <-"ssd" #ddply doesn't seem to like spaces in column names, or ""ing them

cssd<-ddply(alltraits2, c("Origin"), summarise,
             N = sum(!is.na(ssd)),
             mean = mean(ssd, na.rm=TRUE),
             sd = sd(ssd, na.rm=TRUE),
             se = sd/sqrt(N))

ggplot(cssd, aes(x=Origin, y=mean)) + geom_bar(position=position_dodge(), stat="identity") + geom_errorbar(aes(ymin=mean-se, ymax = mean+se), width=.2) + theme_bw() + theme (panel.grid.major=element_line(color = NA), panel.grid.minor=element_line(color = NA))+ ylab("SSD")

#plot SLA

names(alltraits2)[names(alltraits2)=="Leaf specific area (SLA)"] <-"sla" #ddply doesn't seem to like spaces in column names, or ""ing them

csla<-ddply(alltraits2, c("Origin"), summarise,
             N = sum(!is.na(sla)),
             mean = mean(sla, na.rm=TRUE),
             sd = sd(sla, na.rm=TRUE),
             se = sd/sqrt(N))

ggplot(csla, aes(x=Origin, y=mean)) + geom_bar(position=position_dodge(), stat="identity") + geom_errorbar(aes(ymin=mean-se, ymax = mean+se), width=.2) + theme_bw() + theme (panel.grid.major=element_line(color = NA), panel.grid.minor=element_line(color = NA))+ ylab("SLA")

#plot leaf N per dry mass

names(alltraits2)[names(alltraits2)=="Leaf nitrogen (N) content per dry mass"] <-"leafN" #ddply doesn't seem to like spaces in column names, or ""ing them

cleafN<-ddply(alltraits2, c("Origin"), summarise,
             N = sum(!is.na(leafN)),
             mean = mean(leafN, na.rm=TRUE),
             sd = sd(leafN, na.rm=TRUE),
             se = sd/sqrt(N))

ggplot(cleafN, aes(x=Origin, y=mean)) + geom_bar(position=position_dodge(), stat="identity") + geom_errorbar(aes(ymin=mean-se, ymax = mean+se), width=.2) + theme_bw() + theme (panel.grid.major=element_line(color = NA), panel.grid.minor=element_line(color = NA))+ ylab("Leaf N per dry mass (mg/g)")


```




------------------------------------------------------------------------------------
*Null community assembly*

http://stackoverflow.com/questions/6422273/how-to-randomize-or-permute-a-dataframe-rowwise-and-columnwise

use sample or permatswap in vegan or randomizeMatrix in picante

```{r}
require(vegan)

#I think I have to use count data for this rather than cover data
matrix<-read.csv("2012_abundancematrix_modified.csv")
row.names(matrix)<-matrix$Site
comm<-matrix[,4:246]
test<-permatswap(comm, method="quasiswap", fixedmar="both", shuffle = "samp", strata = NULL, mtype="count", times=99)



#somehow need to iterate FD across this
#need to load in the traits data
require(picante)
require(FD)
rep=99
permute<-matrix(nrow=rep, ncol=4)
for (i in 1:rep) {
  temp<-randomizeMatrix(cover, null.model="independentswap", iterations = 1000)
  FDtemp<-dbFD(pref_traits, temp, stand.x=TRUE, ord="podani", corr = "cailliez") #this is silly I don't need FD in here, I need something like NND and maxD after Mouillot et al.  but maybe this will tell me something else 
  permute[i, ] <-c(mean(FDtemp$FEve), mean(FDtemp$FDiv), mean(FDtemp$FDis), mean(FDtemp$RaoQ))
}

FEvehist<-permute[,1]
hist(FEvehist, breaks=100)
abline(v=0.670, lwd=2, col="purple") #this isn't plotting and also is an inaccurate test since i am plotting a single community value on a histogram of mean FEves across all communities.  

#maybe make an array and save the value for each community and test each community against its own null distribution??
#this isn't working
#require(picante)
#require(FD)
#rep=2
#array<-array(0, dim=c(rep,24,4))
#for (i in 1:rep) {
 # temp<-randomizeMatrix(cover, null.model="independentswap", iterations = 1000)
 # FDtemp<-dbFD(pref_traits, temp, stand.x=TRUE, ord="podani", corr = "cailliez")
 # FEve = FDtemp$FEve
 # FDiv = FDtemp$FDiv
 # FDis = FDtemp$FDis
#  RaoQ = FDtemp$RaoQ
#  for (j in 1:24){
#  array[i,j, ] <-c(FEve, FDiv, FDis, RaoQ)
#  }
#}

#Trying a different approach

require(picante)
require(FD)
rep=99
permFEve<-matrix(nrow=rep, ncol=24)
permFDiv<-matrix(nrow=rep, ncol=24)
permFDis<-matrix(nrow=rep, ncol=24)
permRaoQ<-matrix(nrow=rep, ncol=24)
for (i in 11:rep) {
  temp<-randomizeMatrix(cover, null.model="independentswap", iterations = 1000)
  try(FDtemp<-dbFD(pref_traits, temp, stand.x=TRUE, ord="podani", corr = "cailliez"), silent=TRUE)
  FEve = FDtemp$FEve
  FDiv = FDtemp$FDiv
  FDis = FDtemp$FDis
  RaoQ = FDtemp$RaoQ
  permFEve[i,]<-FEve
  permFDiv[i,]<-FDiv
  permFDis[i,]<-FDis
  permRaoQ[i,]<-RaoQ
}

#this will provide each row as a permutation and each column as one of the communities, with a separate table for each statistic.  This can be used to test each community for environmental filtering etc once I figure out how to calculate probabilities on the histogram i made)

is it just if my values fall outside 0.025 and .975?  

#Export the null tables so I don't have to run this again.  

write.table(permFDis, file="nullFDis.csv", sep=",")
write.table(permFDiv, file="nullFDiv.csv", sep=",")
write.table(permFEve, file="nullFEve.csv", sep=",")
write.table(permRaoQ, file="nullRaoQ.csv", sep=",")

FDiv<-read.csv("nullFDiv.csv", row.names=1)

hist(FDiv$B1GH, breaks=20)
mean.FDiv=mean(FDiv$B1GH, na.rm=T)
var.FDiv=var(FDiv$B1GH, na.rm=T)
sd.FDiv=sd(FDiv$B1GH, na.rm=T)
max.FDiv=max(FDiv$B1GH, na.rm=T)


hist(FDiv$B1GH, breaks=20, freq=F, xlab = "Functional Diversity", ylab='Probability')
lines(density(FDiv$B1GH, na.rm=T, from=0, to=max.FDiv), lwd=2)



lines(density(FDiv$B1GH), lwd=2)

```

#get quantiles
quant.hu <- apply(test, 2, quantile, probs = c(.025, .975))
q.dat <- melt(data.frame(t(quant.hu)))
q.dat2 <- cbind(q.dat, num=rep(1:25, 2))

Code for checking the distribution - plotting a dist on a histogram???
> hist(traitsdiv$FDiv)
> x<-traitsdiv$FDiv
> h<-hist(x, breaks=10)
> xfit<-seq(min(x), max(x), length=40)
> yfit<-dpoisson(xfit, mean=mean(x), sd=sd(x))
Error: could not find function "dpoisson"
> ??functions
> yfit<-ppois(xfit, mean=mean(x), sd=sd(x))
Error in ppois(xfit, mean = mean(x), sd = sd(x)) : 
  unused arguments (mean = mean(x), sd = sd(x))
> yfit<-ppois(xfit)
Error in ppois(xfit) : argument "lambda" is missing, with no default
> yfit<-ppois(xfit)
Error in ppois(xfit) : argument "lambda" is missing, with no default
> help(ppois)
> yfit<-ppois(xfit, lambda=mean(x))
> yfit<-yfit*diff(h$mids[1:2]*length(x))
> lines(xfit, yfit, col="blue", lwd=2)

JUNK LEFTOVER CODE
------------------------------------------------------------


trying new package 'cati'
```{r}
require(cati)
#transpose the community matrix
comm_tp<-(cover)
comm_tp<-as.data.frame(comm_tp)
indtraits<-AbToInd(sitebytrait_noNA, comm_tp, type.sp.val = "abundance")

ComIndex(traits = indtraits)


```



trying code to generate null communities myself
```{r}
reps<-100  #Number of replicates for each sample size
sites<-data.frame(as.factor(rownames(cover)))#sample sizes, in number of represented individuals
colnames(sites)[1]="sites"
sites_tp<-t(sites)
samples<-array(0,dim=c(2, length(sites_tp), reps))


for (j in 1:reps){
  samples[j, ] <-sample()
  
  
  


#so the method is to decide on the statistic that measures limiting similarity (and then environmental filtering), generate a null community, calculate that statistics, and iterate that enough times that i have a probability distribution of that statistic against which i can test each of my observeds.  use all species ever observed for null


#need to randomize the occurrence (cover) matrix keeping rows and column sums constant.  on each randomization calculate the statistic, save that, randomize again.


#pool.range<-c(20,100)    #range of species richness of total species pool (includes natives, exotics, and "bare spaces")
#NEprop<-c(.75,.15,.1)   #proportion of, respectively, natives, exotics, and bare spaces in pool (totals to 1)

#tot.pool<-round(runif(reps,pool.range[1],pool.range[2]))  #randomly generate [reps]-length vector of total pool sizes

#make a output matrix to fill all the different simulations (why we have a third dimension, so that it does not replace the earlier matrix)

http://stackoverflow.com/questions/24314878/compute-all-pairwise-differences-within-a-vector-in-r

min NND - for species i:length(species) in sites j:length(sites), calculate all pairwise distances using gowdist matrix and save the smallest of these.  

for (i in 1:sites){
  pairdist<-(j:k - j:k)   abs(apply(combn(1:length(species),2),2,diff))
  mNND<-min(pairdist[,2])
  
}


http://stackoverflow.com/questions/6422273/how-to-randomize-or-permute-a-dataframe-rowwise-and-columnwise

use sample or permatswap in vegan or randomizeMatrix in picante

output<-array(0,dim=c(2,length(sites),reps))

#loop to simulate the matrixes

for (j in 1:reps){

#determine pool composition for replicate
natives<-paste("N",c(1:round(NEprop[1]*tot.pool[j])))   #list of native species
exotics<-paste("E",c(1:round(NEprop[2]*tot.pool[j])))   #list of exotic species
zeros<-paste("Z",c(1:round(NEprop[3]*tot.pool[j]))) 
#list of free spaces
#allspp<-c(natives,exotics,zeros)                
#list of all species and blanks
  

#randomly construct simulated community

#ind.vec<-floor(rlnorm(length(allspp),8,1))      
#create list of abundances for each species, from lognormal abundance distribution

allspp<-paste("Species", c(1:round()))
comm<-rep(allspp[1],ind.vec[1])         
#populate first species in pool with its associated abundance

for(i in 2:length(allspp)) {            
#loop over all remaining species

comm<-c(comm,rep(allspp[i],ind.vec[i]))     
#populate remaining species with associated abundances

  }                         #close loop

for(i in 1:length(samps)) {                     
#Loop for different sample sizes

rs<-sample(comm,samps[i])                   #draw randomly from community pool of individuals with given sample size

output[1,i,j]<-length(unique(rs[is.element(rs,natives)]))   #total richness of natives in the sample

output[2,i,j]<-length(unique(rs[is.element(rs,exotics)]))   #total richness of exotics in the sample

}}  #end sample size loop






```





Nathan Kraft's test for null community assembly of traits (http://life.umd.edu/biology/kraftlab/Code_files/trait_tests.R)

The initial script defining functions (run before adding my own data)
///this only works for one trait.///
```{r}
## Nathan Kraft
## University of California, Berkeley 
## and currently
## Biodiversity Research Centre, University of British Columbia
## nkraft@biodiversity.ubc.ca

## Trait-based tests of community assembly in R

#The R functions posted here are free for you to download and use (under the terms of GNU GPL v2). The code offered is unsupported- I make no claims that they will work with your data or increase your general well being- but I am happy to answer questions. Please consider citing the related papers if you use them, modify them in your own research, or figure out how to solve a problem by looking at them.

## Simplification of functions used in:

#Kraft, N. J. B. and D. D. Ackerly. 2010. Functional trait and phylogenetic tests of community assembly across spatial scales in an Amazonian forest. Ecological Monographs 80:401-422.

#Kraft, N. J. B., R. Valencia, and D. Ackerly. 2008. Functional traits and niche-based tree community assembly in an Amazonian forest. Science 322:580-582.


# Fuctions come first in the file; example is at end. The key function is test_trait_data(); it requires all the other functions to run properly. 

## As a general warning, there is MINIMAL error/ safety checking in this code.  Use the example at the end of the file for formatting your data- I highly recommend that you wrap this code in something else to ensure that only complete datasets go into this function.  Also- Kurtosis is undefined for samples of less than 4, so the minimum community size for these tests is 4.  

## UPDATED June 5 2012 to correct an error in the calculation of SDNDr. 

#####################
### Functions #######
###########################################################



## BASIC TRAIT SPACE FUNCTIONS:

# Function to calculate the unbiased population estimate or the biased sample statistic of kurtosis. from http://www2.jura.uni-hamburg.de/instkrim/kriminologie/Mitarbeiter/Enzmann/Software/kurtosis.r Aug 2 2007


kurtosis=function(x, biased=F, na.rm=T)

{
 if (na.rm==T) x = x[!is.na(x)]
 n = length(x)
 if (n < 4)
 {
   if (na.rm==T)
   {
      cat('valid cases = ',n,'\nkurtosis is not defined for less than 4 valid cases!\n')
   }
   else
   {
      cat('cases = ',n,'\nkurtosis is not defined for less than 4 cases!\n')
   }
 }
 else
 {
   if (biased==T)
   {
      z = sqrt(n/(n-1))*scale(x)
      k = mean(z^4)-3
   }
   else
   {
      z = scale(x)
      k = sum(z^4)*n*(n+1)/((n-1)*(n-2)*(n-3))-3*(n-1)^2/((n-2)*(n-3))
   }
 k
 }
}

get_kurt=function(vect){
  return(kurtosis(vect))
	}

get_range=function(vect){
	r<-range(vect, na.rm=TRUE)
	return(r[2]-r[1])
	}
	
get_spacing=function(vect){
	vect<-vect[!is.na(vect)]
	vect[order(vect)]->v
	n<-length(v)
	spacing=NULL
	summary=NULL
	
	spacing[1]<-abs(v[1]-v[2])
	for (i in 2:(n-1)){
		first<-abs(v[i]-v[i-1])
		second<-abs(v[i]-v[i+1])
		spacing[i]<-min(first, second)
		}
	spacing[(length(spacing)+1)]<-abs(v[n]-v[n-1])
	summary$SDNN<-sd(spacing)
	summary$SDND<-sd(diff(sort(vect)))
	return(summary)
	}

get_var=function(vect){
	return(var(vect, na.rm=TRUE))
	}	
	
	
### Utility functions:
	
trim_pool_to_sample=function(restricted_sample,pool){
	sp<-unique(restricted_sample$sp)
	pool[(pool$sp %in% sp),]->np
	
	return(np)
	
	}


### Function to build a null distribution:

make_null=function(pool,richness,log=TRUE, reps=999, abweight=FALSE, abdata=NULL) {
	##abdata should be a sp x abund DF
	
	summary=NULL
	pool<-pool[!is.na(pool[2]),]
	if(log){
		pool[2]<-log10(pool[2])
		}
	
	if(abweight){
			merge(pool,abdata)->new
			new->pool
			}else{pool$abund<-1}
	

	
	for (i in 1:reps){
		sample(pool[,2], richness, prob=pool$abund)-> simcom
		##trait mean
		summary$mean[i]<-mean(simcom)
		##trait range
		summary$range[i]<-get_range(simcom)
		##spacing stats
		summary$var[i]<-get_var(simcom)
		space<-get_spacing(simcom)
		summary$SDNN[i]<-space$SDNN
		summary$SDNNr[i]<-space$SDNN/summary$range[i]
		summary$SDNDr[i]<-space$SDND/summary$range[i]
		summary$kurt[i]<-get_kurt(simcom)
		
				}
	summary<-as.data.frame(summary)
	return(summary)
	}
	

### Main function that puts it all together:

test_trait_data=function(sp_list, pool, log=TRUE, reps=999,abweight=FALSE, abdata=NULL, verbose=FALSE){
	
	
	community<-pool[pool$sp %in% sp_list,]
	
	dim(community)[1]->richness
	summary=NULL
	summary$test.richness<-richness
	summary$reps<-reps
	
	if(log){community[2]<-log10(community[2])}
	
	make_null(pool,richness, log=log, reps=reps, abweight=abweight, abdata=abdata)->nulldist
	summary$mean_rank<-sum(nulldist$mean<mean(community[,2]))
	summary$range_rank<-sum(nulldist$range<get_range(community[,2]))
	
	obspace<-get_spacing(community[,2])
	summary$SDNN_rank<-	sum(nulldist$SDNN<obspace$SDNN)
	summary$SDNNr_rank<-sum(nulldist$SDNNr<(obspace$SDNN/get_range(community[,2])))
	summary$SDNDr_rank<- sum(nulldist$SDNDr<(obspace$SDND/get_range(community[,2])))
	summary$kurt_rank<-	sum(nulldist$kurt<get_kurt(community[,2]))
	summary$var_rank<-	sum(nulldist$var<get_var(community[,2]))
	summary<-as.data.frame(summary)
	
	

	summary$obs_mean<-mean(community[,2])
	summary$null_mean_mean<-mean(nulldist$mean)
	summary$null_mean_sd<-sd(nulldist$mean)
		
	summary$obs_range<-get_range(community[,2])
	summary$null_mean_range<-mean(nulldist$range)
	summary$null_range_sd<-sd(nulldist$range)
		
	summary$obs_SDNN<-obspace$SDNN
	summary$null_mean_SDNN<-mean(nulldist$SDNN)
	summary$null_SDNN_sd<-sd(nulldist$SDNN)
		
	summary$obs_kurt<-get_kurt(community[,2])
	summary$null_mean_kurt<-mean(nulldist$kurt)
	summary$null_kurt_sd<-sd(nulldist$kurt)
		
	summary$obs_var<-get_var(community[,2])
	summary$null_mean_var<-mean(nulldist$var)
	summary$null_var_sd<-sd(nulldist$var)
		
	summary$obs_SDNNr<-summary$obs_SDNN/summary$obs_range
	summary$null_mean_SDNNr<-mean(nulldist$SDNNr)
	summary$null_SDNNr_sd<-sd(nulldist$SDNNr)
		
	summary$obs_SDNDr<-obspace$SDND/summary$obs_range
	summary$null_mean_SDNDr<-mean(nulldist$SDNDr)
	summary$null_SDNDr_sd<-sd(nulldist$SDNDr)

	
	summary$mean_ES<-(summary$obs_mean-summary$null_mean_mean )/summary$null_mean_sd
	summary$range_ES<-(summary$obs_range-summary$null_mean_range )/summary$null_range_sd
	summary$var_ES<-(summary$obs_var-summary$null_mean_var )/summary$null_var_sd
	summary$SDNN_ES<-(summary$obs_SDNN-summary$null_mean_SDNN )/summary$null_SDNN_sd
	summary$SDNNr_ES<-(summary$obs_SDNNr-summary$null_mean_SDNNr )/summary$null_SDNNr_sd
	summary$SDNDr_ES<-(summary$obs_SDNDr-summary$null_mean_SDNDr )/summary$null_SDNDr_sd
	summary$kurt_ES<-(summary$obs_kurt-summary$null_mean_kurt )/summary$null_kurt_sd
	
	if(verbose){
		return(summary)
		}else{ 
			return(summary[,c("test.richness", "reps", "mean_rank", "mean_ES", "range_rank", "range_ES", "var_rank", "var_ES", "SDNN_rank", "SDNN_ES", "SDNNr_rank", "SDNNr_ES", "SDNDr_rank", "SDNDr_ES", "kurt_rank", "kurt_ES")])  
			
			}
	
}

##################################
## END of functions ####
########################
```


then the actual analysis

```{r}
# note that all of the above code must be run in the console before the example below will function:


#####################################
## simple example with random data ##
#####################################

## Species list for a community to be tested:
sp_list_community<-c("a", "b","c","d", "e")


## the species pool to test the species list against (note that it must contain all species in the community!)
sp<-c("a", "b","c","d", "e", "f", "g", "h", "i", "j", "k", "l")
trait<-rlnorm(12,mean=5, sd=2)

pool<-data.frame(sp, trait)


##optional abundance vector for the species pool; must be in the same order as the species in the species pool data frame:
abundance<-floor(rlnorm(12,mean=5, sd=1))


## Example test, weighting species by abunance and log transforming the trait data prior to analysis:

test_trait_data(sp_list_community, pool, log=TRUE, reps=999, abweight=TRUE, abdata=abundance, verbose=TRUE)->summary_verbose

###if you just need effect sizes and ranks, set verbose=FALSE:
test_trait_data(sp_list_community, pool, log=TRUE, reps=999, abweight=TRUE, abdata=abundance, verbose=FALSE)->summary

### abundance weighting will change the output!
test_trait_data(sp_list_community, pool, log=TRUE, reps=999, abweight=FALSE, verbose=FALSE)->summary_pres_abs


## Description of arguments for test_trait_data()
#  sp_list  = vector of species names for local community
#  pool  	= data frame for species pool, col 1 must be named "sp" and includes species names, used to match to sp_list; col 2 can be called anything and is a continuous trait
#  log		= Logical- should trait data be logged?
#  reps		= number of null communities to build- should be no less than 999
#  abweight = logical- should species be sampled in the null based on abundance? If true, requires a vector for abdata
#  abdata   = vector of the abundances (absolute or relative) of species in the pool, used to weight null model draws.  Must be in same order as species in pool dataframe.  Required if abweight is TRUE.
#  verbose  = Logical.  How much information do you want in the output?  If FALSE, summary includes the ranks of the observed in the null and effect sizes.  If TRUE, summary also includes the observed value, the mean of the null, and the sd of the null for each metric.

## Description of output:
# test.richness = number of species in the community.
# reps 			= number of null randomizations performed
# ..._rank		= rank of the observed metric (e.g. range_rank) in the null.  Used with 'reps' to calculate a p-value.
# ..._ES		= standard effect size for a metric (e.g. range_ES), calculated as (obs-expected)/ (sd of null)
# obs_...		= value of a metric for the real community (e.g. obs_range)
# null_mean_... = mean of the null distribution of a given metric (e.g. null_mean_range)
# null_..._sd	= standard deviation of the null distrbution for a given metric (e.g. null_range_sd)

```
Trying a different package

```{r}
require(StatMatch)
test<-gower.dist(cover, traits)

require(cluster)
test<-daisy(traits, metric = "euclidean")
test<-as.data.frame(test)

require(vegan)  #this is working
test<-cca(cover, sitebytrait_noNA)
plot(test, type="n")
text(test, display="bp")
text(test, display="species")


test2<-test$CWM
```

-

Import a new community dataset with cover values
```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/2012_specieslist_herbcover.csv") #insert the  raw URL for the data file on github here
comm_cover_temp<- read.csv(text = raw) #read in the github file
```

Trim cover dataset to needed columns and read cover as numeric
```{r}
comm_cover_temp<-comm_cover_temp[,c(5:7,9)]
comm_cover_list<-rename(comm_cover_temp, c("Site.1"="Site", "Cover.."="Cover"))
comm_cover_list$Cover<-sapply(comm_cover_list$Cover, as.character)
comm_cover_list$Cover<-sapply(comm_cover_list$Cover, as.numeric)
```

Make a species cover matrix
```{r}
require(reshape)
comm_cover<-cast(comm_cover_list, Site ~ Species, value="Cover", fun.aggregate=sum)
comm_cover_quad<-as.data.frame(comm_cover_quad)
```


To make the NANs something else

quadmat[is.na(quadmat)] <- 00 #refills the empty cells with 0

to view the full dataset
```{r}
utils::View(comm)
```

///All below are practice - now deprecated code for a set of the traits data that had not been cleaned for units consistency, etc///

Import the list of quantitative traits and make sure all values are numeric
n.b. apparently if numeric values read in as factors, you have to go through converting to as.character and then to as.numeric to avoid R changing the values of the numbers in that column (which it was doing when I only used as.numeric)
there are a number of "x" values in the cover list, which were presences with such a minimal cover as to essentially be zero.  these are at the moment tranformed into NAs in this code and therefore absences

```{r}
require(RCurl)
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
raw <- getURL("https://raw.githubusercontent.com/erollinson/Dissertation/master/TRY_quant_traits.csv") #insert the  raw URL for the data file on github here
traitstemp<- read.csv(text = raw) #read in the github file
traitstemp$Value<-sapply(traitstemp$Value, as.character)
traitstemp$Value<-sapply(traitstemp$Value, as.numeric)
```

Turn the traits list into a matrix, put  n/a for species/trait cells that do not have data
```{r}
require(reshape)
traitmatrix<-cast(traitstemp, Trait ~ Species, value='Value', fun.aggregate=mean)
```

to view the full dataset
```{r}
utils::View(comm)
```

export the traits list and community cover lists to Excel, since they have some mismatches in species content

oh - probably because it contains all species and the community list just contains herbaceous species at the moment because that is the only group of plants with cover estimates - so we're exporting to make a list with just herbaceous species.  Additionally the full traits list requested all species observed in 2012 intensive sampling and 2013 extensive sampling; not all 2013 species were observed in 2012, and those are removed from the truncated list as well
n.b. acer saccharum is still in both lists, seedlings had cover estimates

will need to rename Athyrium filix-femina var. angustum in comm data to Athyrium filix-femina to match trait data
same for Circaea lutetiana ssp. canadensis -> Circaea lutetiana
Maianthemum racemosum ssp. racemosum -> Maianthemum racemosum
also need to remove anything Genus sp. from comm list, and all the SP##
fix typo in comm, Hyperium mutilum to Hypericum mutilum

```{r}
write.table(traitmatrix, file="TRY_traitsmatrix.csv", sep=",", row.names=F)
write.table(comm_cover, file="2012_comm_cover.csv", sep=",", row.names=F)
```


reimport the data edited as above
```{r}
#community
comm2012<-read.csv("2012_comm_cover_herbs.csv")
rownames(comm2012)<-comm2012$Site
comm2012<-comm2012[,2:166]

#traits
traits2012<-read.csv("2012_TRY_traitsmatrix_herbs.csv")
rownames(traits2012)<-traits2012$Trait
traits2012<-traits2012[,2:166]

```


editing the dissimilarity matrix in excel: if a species has 5 or fewer missing distances, interpolate.  more than 5, remove species from analysis.

removed species (n=34):

Carex bullata
Didiplis.diandra
Dryopteris.camyloptera
Dryopteris.marginalis
Echinochloa.muricata
Eurybia.divaricata  
Eutrochium.purpureum
Halenia.deflexa
Hydrocotyle.americana
Hylotelephium.telephium
Lactuca.canadensis
Muhlenbergia.sobolifera
Oxalis.grandis
Paspalum.setaceum
Polygonum.arifolium
Polygonum.cespitosum
Polystichum.acrostichoides  
Potentilla.simplex
Rubus.pubescens
Rumex.triangulivalvis 
Sanicula.odorata
Scirpus.polyphyllus
Sinapis.arvensis
Smilax.glauca
Solanum.ptycanthum
Stellaria.pubera
Symphyotrichum.dumosum
Symphyotrichum.lateriflorum
Teucrium.canadense
Thalictrum.thalictroides
Trifolium.arvense 
Trifolium.campestre
Viola.fimbriatula
Viola.pubescens

```{r}
trim_trait_dis<-read.csv("2012_trait_dissimilarity_trim_averaged_NAs.csv")
rownames(trim_trait_dis)<-trim_trait_dis$X
trim_trait_dis<-trim_trait_dis[,2:132]
trim_trait_dis<-as.matrix(trim_trait_dis)
fit<-isoMDS(trim_trait_dis, k=2)
fit
x<-fit$points[,1]
y<-fit$points[,2]
plot(x,y)
```

rownames(traits2012)<-traits2012$Trait
traits2012<-traits2012[,2:132]


Make a trait dissimilarity matrix for the species
```{r}
require(cluster)
traitdiss<-daisy(traits2012trans2, metric = "euclidean")
traitdissim<-as.matrix(traitdiss)

#try FD again with trait dissim? - no, it won't allow NAs with that
#do I want gower or a different dissimilarity?

I think I can work with this dissimilarity matrix or another one and make decisions about interpolating NAs or deleting certain species or traits

write.table(traitdissim, file="2012_trait_dissimilarity.csv", sep=",", row.names=T)


```


It might be best to try the method as outlined in the proposal first using just a handful of traits, by hand, and then extend to the larger dataset at a later date.  Check - which traits show the most variation?  plot histograms

The partitioning of variation in trait states will work better with the qualitative traits, stick with those for the stuff by hand.  


Need to create a matrix with trait abundance values (site by trait, derived from site by species).  Potentially follow method in Ackerly and Cornwell 2007?

fill a new matrix - for each community, make columns for each trait, average trait values for each species in the community

would a species by trait matrix help?


Trying a new method RLQ following https://climateecology.wordpress.com/2013/09/03/r-for-ecologists-rlq-analysis-semi-explained/ (this will be great to transfer into the extensive sampling analysis as well, if it works with presence/absence; in the meantime just borrowing some info).  ok maybe not so helpful here

